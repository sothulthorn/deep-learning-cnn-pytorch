{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision의 models 모듈 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def create_resnet_model(model_name, num_classes=10, weights=None):\n",
    "    model = None\n",
    "    if model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=weights)\n",
    "    elif model_name == 'resnext50_32x4d':\n",
    "        model = models.resnext50_32x4d(weights=weights)\n",
    "    \n",
    "    num_in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features=num_in_features, out_features=num_classes)\n",
    "\n",
    "    return model\n",
    "    \n",
    "model = create_resnet_model('resnet50', num_classes=2, weights='DEFAULT') #resnet50, resnext50_32x4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개와 고양이 데이터 세트 다운로드 후 메타 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_cnd_meta_df(file_dir):\n",
    "    paths = [] # 이미지 파일 경로 리스트\n",
    "    dataset_gubuns = [] # 학습과 테스트\n",
    "    label_gubuns = [] # 개와 고양이\n",
    "    # os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n",
    "    # cat-and-dog 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n",
    "    # cat-and-dog 밑으로 /train/, /test/ 하위 디렉토리 존재(학습, 테스트 용 이미지 파일들을 가짐)\n",
    "    for dirname, _, filenames in os.walk(file_dir):\n",
    "        for filename in filenames:\n",
    "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
    "            if '.jpg' in filename:\n",
    "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
    "                file_path = dirname+'/'+ filename\n",
    "                paths.append(file_path)\n",
    "                # 파일의 절대 경로에 training_set, test_set가 포함되어 있으면 데이터 세트 구분을 'train'과 'test'로 분류. \n",
    "                if '/training_set/' in file_path:\n",
    "                    dataset_gubuns.append('train')  \n",
    "                elif '/test_set/' in file_path:\n",
    "                    dataset_gubuns.append('test')\n",
    "                else: dataset_gubuns.append('N/A')\n",
    "                \n",
    "                # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n",
    "                if 'dogs' in file_path:\n",
    "                    label_gubuns.append('DOG')\n",
    "                elif 'cats' in file_path:\n",
    "                    label_gubuns.append('CAT')\n",
    "                else: label_gubuns.append('N/A')\n",
    "    # DataFrame 메타 데이터 생성. \n",
    "    data_df = pd.DataFrame({'path':paths, \n",
    "                            'dataset':dataset_gubuns, \n",
    "                            'label':label_gubuns})\n",
    "    # Target값 0, 1 변환\n",
    "    label_mapping = {'DOG': 0, 'CAT': 1}\n",
    "    data_df['target'] = data_df['label'].map(label_mapping)\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습, 검증, 테스트 데이터로 나누고 Dataset 및 DataLoader 생성\n",
    "* 학습 시간을 줄이기 위해서 학습과 검증 데이터를 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_df = create_cnd_meta_df(file_dir='/kaggle/input/')\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 전체 데이터 세트에서 학습과 테스트용 메타 정보 DataFrame 생성. \n",
    "train_df = data_df[data_df['dataset']=='train']\n",
    "test_df = data_df[data_df['dataset']=='test']\n",
    "\n",
    "# train_df의 50%를 train_df_temp로 할당. \n",
    "train_df_temp, _ = train_test_split(train_df, test_size=0.5, stratify=train_df['target'], random_state=2025)\n",
    "\n",
    "# 다시 train_df_temp의 50%씩 tr_df와 val_df로 할당.   \n",
    "tr_df, val_df = train_test_split(train_df_temp, test_size=0.5, stratify=train_df_temp['target'], random_state=2025)\n",
    "\n",
    "print(data_df.shape, train_df.shape, tr_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 및 학습/검증용 DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class CnD_Dataset(Dataset):\n",
    "    # 이미지 파일리스트, 타겟 파일리스트, transforms 등 이미지와 타겟 데이터 가공에 필요한 인자들을 입력 받음\n",
    "    def __init__(self, image_paths, targets=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    # 전체 건수를 반환\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    # idx로 지정된 하나의 image, label을 tensor 형태로 반환\n",
    "    def __getitem__(self, idx):    \n",
    "        # PIL을 이용하여 이미지 로딩하고 PIL Image 객체 반환.\n",
    "        pil_image = Image.open(self.image_paths[idx])\n",
    "        # 보통은 transform이 None이 되는 경우는 거의 없음(Tensor 변환이라도 있음)\n",
    "        image = self.transform(pil_image)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            # 개별 target값을 tensor로 변환.\n",
    "            target = torch.tensor(self.targets[idx])\n",
    "            return image, target\n",
    "        # 테스트 데이터의 경우 targets가 입력 되지 않을 수 있으므로 이를 대비. \n",
    "        else:\n",
    "            return image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "IMG_MEANS = [0.485, 0.456, 0.406] # ImageNet 데이터세트의 이미지 채널별 평균값\n",
    "IMG_STD = [0.229, 0.224, 0.225] # ImageNet 데이터세트의 이미지 채널별 표준편차값\n",
    "\n",
    "def create_tr_val_loader(tr_df, val_df, transform):\n",
    "    tr_dataset = CnD_Dataset(image_paths=tr_df['path'].to_list(), \n",
    "                            targets=tr_df['target'].to_list(), transform=transform)\n",
    "    val_dataset = CnD_Dataset(image_paths=val_df['path'].to_list(), \n",
    "                            targets=val_df['target'].to_list(), transform=transform)\n",
    "    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return tr_loader, val_loader\n",
    "\n",
    "transform_01 = T.Compose([\n",
    "            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n",
    "            T.ToTensor(), T.Normalize(mean=IMG_MEANS, std=IMG_STD)\n",
    "])\n",
    "\n",
    "tr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=transform_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer Class 생성 - ModelCheckpoint와 Early Stopping 로직 적용\n",
    "* 생성인자에 checkpoint_dir과 early_patience 인자 추가. \n",
    "* fit() 메소드에 ModelCheckpoint와 Early Stopping 로직을 적용함.\n",
    "* pytorch는 모델을 저장하는데,\n",
    "    * torch.save(model, '저장명.pt'): 모델 아키텍처(optimizer 까지)와 parameter(weight)가 함께 저장.\n",
    "    * torch.save(model.state_dict(), 'model_state_저장명.pt'): parameter 만 저장. 더 자주 사용됨.\n",
    "* pytorch 모델 load 방식\n",
    "    * model = torch.load('저장명.pt'): 모델 전체(아키텍처와 parameter까지 한번에)\n",
    "    * model.load_state_dict(torch.load('model_state_저장명.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Trainer_01:\n",
    "    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n",
    "                 checkpoint_dir='/kaggle/working/checkpoints', early_patience=5, device=None):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        # scheduler 추가\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # 현재 learning rate 변수 추가\n",
    "        self.current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        #checkpoint와 early stopping 관련 변수 설정\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.early_patience = early_patience\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.early_stopping_counter = 0\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0.0\n",
    "        running_avg_loss = 0.0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        # tqdm으로 실시간 training loop 진행 상황 시각화\n",
    "        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
    "                # 반드시 to(self.device). to(device) 아님.\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                accu_loss += loss.item()\n",
    "                running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                # accuracy metric 계산\n",
    "                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                num_total += inputs.shape[0]\n",
    "                accu_num_correct += num_correct\n",
    "                accuracy = accu_num_correct / num_total\n",
    "\n",
    "                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                progress_bar.update(1)\n",
    "                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                              \"Accuracy\": accuracy})\n",
    "\n",
    "        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n",
    "            self.scheduler.step()\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "        \n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def validate_epoch(self, epoch):\n",
    "        if not self.val_loader:\n",
    "            return None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0\n",
    "        running_avg_loss = 0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    loss = self.loss_fn(outputs, targets)\n",
    "                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                    accu_loss += loss.item()\n",
    "                    running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                    # accuracy metric 계산\n",
    "                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    accuracy = accu_num_correct / num_total\n",
    "                    \n",
    "                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 40 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                                  \"Accuracy\":accuracy})\n",
    "        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n",
    "        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step(running_avg_loss)\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate_epoch(epoch)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n",
    "                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n",
    "                  f\", Current lr:{self.current_lr:.6f}\")\n",
    "            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n",
    "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(self.current_lr)\n",
    "\n",
    "            # 현재 loss가 이전 best_val_loss보다 향상되면(작아지면)\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                # model weight 저장.\n",
    "                self.save_checkpoint(epoch, val_loss)                \n",
    "                # early_stopping_counter 초기화\n",
    "                self.early_stopping_counter = 0\n",
    "            else:\n",
    "                self.early_stopping_counter += 1\n",
    "                if self.early_stopping_counter >= self.early_patience:\n",
    "                    print('Early Stopping happens and trains stops')\n",
    "                    # for epochs loop 문을 빠져나가서 더 이상 학습을 수행하지 않음. \n",
    "                    break\n",
    "                                \n",
    "        return history\n",
    "\n",
    "    # 성능이 이전 epoch 대비 향상되었을 때 파일로 모델 저장. \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch+1}_loss_{val_loss:.4f}.pt')\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model checkpoint at {checkpoint_path}\")\n",
    "\n",
    "    # 학습이 완료된 모델을 return\n",
    "    def get_trained_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변경된 Trainer 클래스를 적용하여 학습 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = create_resnet_model('resnet50', num_classes=2, weights='DEFAULT')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001) # model.fc.parameters(), weight_decay=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Patience를 5로 증가. \n",
    "scheduler = ReduceLROnPlateau(\n",
    "            optimizer=optimizer, mode='min', factor=0.5, patience=5, threshold=0.01, min_lr=0.00001)\n",
    "\n",
    "# checkpoint 파일이 저장될 디렉토리와 early-stop patience 값 입력. \n",
    "trainer = Trainer_01(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "                  train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, \n",
    "                  checkpoint_dir='checkpoints', early_patience=3,\n",
    "                  device=device)\n",
    "# 학습 및 평가\n",
    "history = trainer.fit(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        # 현재 입력으로 들어온 데이터의 batch 통계(mean, variance)를 사용하지 않고, 학습 시 계산된 running 통계값을 사용\n",
    "        self.model.eval()\n",
    "        eval_metric = 0.0\n",
    "        # 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "\n",
    "        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "                    pred = self.model(inputs)\n",
    "\n",
    "                    # 정확도 계산을 위해 누적 전체 건수와 누적 전체 num_correct 건수 계산  \n",
    "                    num_correct = (pred.argmax(-1) == targets).sum().item()\n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    eval_metric = accu_num_correct / num_total\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n",
    "                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n",
    "        \n",
    "        return eval_metric\n",
    "\n",
    "    def predict_proba(self, inputs):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            #예측값을 반환하므로 targets은 필요 없음.\n",
    "            #targets = targets.to(self.device)\n",
    "            pred_proba = F.softmax(outputs, dim=-1) #또는 dim=1\n",
    "\n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        pred_proba = self.predict_proba(inputs)\n",
    "        pred_class = torch.argmax(pred_proba, dim=-1)\n",
    "\n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_image_paths = test_df['path'].to_list()\n",
    "test_targets = test_df['target'].to_list()\n",
    "\n",
    "IMG_SIZE=224\n",
    "test_transform = T.Compose([\n",
    "                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n",
    "                        T.ToTensor(), \n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = CnD_Dataset(image_paths=test_image_paths, \n",
    "                            targets=test_targets, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trained_model = trainer.get_trained_model()\n",
    "\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 생성 파일 확인\n",
    "* /kaggle/working/checkpoints 디렉토리에 생성된 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('/kaggle/working/checkpoints/checkpoint_epoch_3_loss_0.1836.pt', weights_only=True)\n",
    "\n",
    "# Pretrained Weight가 없는 모델로 생성. \n",
    "new_model = create_resnet_model('resnet50', num_classes=2, weights=None)\n",
    "# 신규 모델에 checkpoint 저장된 파라미터 로딩\n",
    "new_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model인자는 앞에서 checkpoint 파일로 생성된 model\n",
    "predictor = Predictor(model=new_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelCheckpoint 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "class ModelCheckpoint:\n",
    "    def __init__(self, checkpoint_dir='checkpoints', monitor='val_loss', mode='min', save_interval=1, verbose=1):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.verbose = verbose\n",
    "        self.save_interval = save_interval\n",
    "        self._make_checkpoint_dir_unless()\n",
    "\n",
    "    def _make_checkpoint_dir_unless(self):\n",
    "        if not os.path.exists(self.checkpoint_dir):\n",
    "            os.makedirs(self.checkpoint_dir)\n",
    "    \n",
    "    # mode 유형에 따라 metric value값이 이전 epoch시 보다 향상 되었는지 확인하여 True/False 값 return\n",
    "    def is_improvement(self, value):\n",
    "        if self.mode == 'min':\n",
    "            return value < self.best_value\n",
    "        else:\n",
    "            return value > self.best_value\n",
    "\n",
    "    # self.best_value값 update, is_improvement() 반환값이 True인 경우만 수행. \n",
    "    def update_best_value(self, value):\n",
    "        self.best_value = value\n",
    "\n",
    "    def save(self, model, epoch, value):\n",
    "        if self.save_interval == 1:\n",
    "            if self.is_improvement(value):\n",
    "                self._checkpoint_save(model, epoch, value)\n",
    "                self.update_best_value(value)\n",
    "            \n",
    "        elif self.save_interval > 1:\n",
    "            if (epoch + 1) % self.save_interval == 0:\n",
    "                self._checkpoint_save(model, epoch, value)\n",
    "            \n",
    "    def _checkpoint_save(self, model, epoch, value):\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, \n",
    "                                       f'checkpoint_epoch_{epoch+1}_{self.monitor}_{value:.4f}.pt')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        if self.verbose:\n",
    "            print(f\"Saved model checkpoint at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint 클래스가 적용된 Trainer 수정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Trainer_02:\n",
    "    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n",
    "                 checkpoint_cb=None, device=None):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        # scheduler 추가\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # 현재 learning rate 변수 추가\n",
    "        self.current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        #checkpoint와 early stopping 관련 변수 설정\n",
    "        self.checkpoint_cb = checkpoint_cb\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0.0\n",
    "        running_avg_loss = 0.0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        # tqdm으로 실시간 training loop 진행 상황 시각화\n",
    "        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
    "                # 반드시 to(self.device). to(device) 아님.\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                accu_loss += loss.item()\n",
    "                running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                # accuracy metric 계산\n",
    "                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                num_total += inputs.shape[0]\n",
    "                accu_num_correct += num_correct\n",
    "                accuracy = accu_num_correct / num_total\n",
    "\n",
    "                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                progress_bar.update(1)\n",
    "                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                              \"Accuracy\": accuracy})\n",
    "\n",
    "        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n",
    "            self.scheduler.step()\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "        \n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def validate_epoch(self, epoch):\n",
    "        if not self.val_loader:\n",
    "            return None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0\n",
    "        running_avg_loss = 0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    loss = self.loss_fn(outputs, targets)\n",
    "                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                    accu_loss += loss.item()\n",
    "                    running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                    # accuracy metric 계산\n",
    "                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    accuracy = accu_num_correct / num_total\n",
    "                    \n",
    "                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                                  \"Accuracy\":accuracy})\n",
    "        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n",
    "        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step(running_avg_loss)\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate_epoch(epoch)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n",
    "                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n",
    "                  f\", Current lr:{self.current_lr:.6f}\")\n",
    "            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n",
    "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(self.current_lr)\n",
    "\n",
    "            # ModelCheckpoint가 생성인자로 들어올 경우 monitor값에 따라 save() 메소드 호출 \n",
    "            if self.checkpoint_cb:\n",
    "                if self.checkpoint_cb.monitor=='val_loss':    \n",
    "                    self.checkpoint_cb.save(self.model, epoch, val_loss)\n",
    "                elif self.checkpoint_cb.monitor == 'val_acc':\n",
    "                    self.checkpoint_cb.save(self.model, epoch, val_acc)\n",
    "                                \n",
    "        return history\n",
    "\n",
    "    # 성능이 이전 epoch 대비 향상되었을 때 파일로 모델 저장. \n",
    "    # def save_checkpoint(self, epoch, val_loss):\n",
    "    #     checkpoint_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch+1}_loss_{val_loss:.4f}.pt')\n",
    "    #     torch.save(self.model.state_dict(), checkpoint_path)\n",
    "    #     print(f\"Saved model checkpoint at {checkpoint_path}\")\n",
    "\n",
    "    # 학습이 완료된 모델을 return\n",
    "    def get_trained_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = create_resnet_model('resnet50', num_classes=2, weights='DEFAULT')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001) # model.fc.parameters(), weight_decay=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Patience를 5로 증가. \n",
    "scheduler = ReduceLROnPlateau(\n",
    "            optimizer=optimizer, mode='min', factor=0.5, patience=5, threshold=0.01, min_lr=0.00001)\n",
    "\n",
    "# ModelCheckpoint 생성.\n",
    "checkpoint_cb = ModelCheckpoint('checkpoints', monitor='val_loss', mode='min', save_interval=1, verbose=1)\n",
    "# checkpoint_cb = ModelCheckpoint('checkpoints', monitor='val_acc', mode='max', save_interval=1, verbose=1)\n",
    "\n",
    "trainer = Trainer_02(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "                  train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, \n",
    "                  checkpoint_cb = checkpoint_cb,\n",
    "                  device=device)\n",
    "# 학습 및 평가. \n",
    "history = trainer.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, monitor='val_loss', mode='min', early_patience=5, verbose=1):\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.early_patience = early_patience\n",
    "        self.verbose = verbose\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def is_improvement(self, value):\n",
    "        if self.mode == 'min':\n",
    "            return value < self.best_value\n",
    "        else:\n",
    "            return value > self.best_value\n",
    "\n",
    "    def check_early_stop(self, value):\n",
    "        is_early_stopped = False\n",
    "        \n",
    "        if self.is_improvement(value):\n",
    "            self.best_value = value\n",
    "            self.counter = 0\n",
    "            is_early_stopped =False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter}/{self.early_patience}\")\n",
    "            if self.counter >= self.early_patience:\n",
    "                is_early_stopped = True\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping happens and train stops\")\n",
    "        \n",
    "        return is_early_stopped\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping과 ModelCheckpoint 반영한 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n",
    "                 callbacks=None, device=None):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        # scheduler 추가\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # 현재 learning rate 변수 추가\n",
    "        self.current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        #checkpoint와 early stopping 클래스들을 list로 받음. \n",
    "        self.callbacks = callbacks\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0.0\n",
    "        running_avg_loss = 0.0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        # tqdm으로 실시간 training loop 진행 상황 시각화\n",
    "        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
    "                # 반드시 to(self.device). to(device) 아님.\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                accu_loss += loss.item()\n",
    "                running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                # accuracy metric 계산\n",
    "                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                num_total += inputs.shape[0]\n",
    "                accu_num_correct += num_correct\n",
    "                accuracy = accu_num_correct / num_total\n",
    "\n",
    "                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                progress_bar.update(1)\n",
    "                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                              \"Accuracy\": accuracy})\n",
    "\n",
    "        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n",
    "            self.scheduler.step()\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "        \n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def validate_epoch(self, epoch):\n",
    "        if not self.val_loader:\n",
    "            return None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # running 평균 loss 계산.\n",
    "        accu_loss = 0\n",
    "        running_avg_loss = 0\n",
    "        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    loss = self.loss_fn(outputs, targets)\n",
    "                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n",
    "                    accu_loss += loss.item()\n",
    "                    running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                    # accuracy metric 계산\n",
    "                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n",
    "                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    accuracy = accu_num_correct / num_total\n",
    "                    \n",
    "                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n",
    "                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                                  \"Accuracy\": accuracy})\n",
    "        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n",
    "        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step(running_avg_loss)\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate_epoch(epoch)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n",
    "                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n",
    "                  f\", Current lr:{self.current_lr:.6f}\")\n",
    "            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n",
    "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(self.current_lr)\n",
    "\n",
    "            # 만약 callbacks가 생성 인자로 들어온 다면 아래 수행. 만약 early stop 되어야 하면 is_epoch_loop_break로 for loop break\n",
    "            if self.callbacks:\n",
    "                is_epoch_loop_break = self._execute_callbacks(self.callbacks, self.model, epoch, val_loss, val_acc)\n",
    "                if is_epoch_loop_break:\n",
    "                    break\n",
    "                                \n",
    "        return history\n",
    "\n",
    "    # 생성 인자로 들어온 callbacks list을 하나씩 꺼내서 ModelCheckpoint, EarlyStopping을 수행. \n",
    "    # EarlyStopping 호출 시 early stop 여부를 판단하는 is_early_stopped 반환\n",
    "    def _execute_callbacks(self, callbacks, model, epoch, val_loss, val_acc):\n",
    "        is_early_stopped = False\n",
    "        \n",
    "        for callback in self.callbacks:\n",
    "            if isinstance(callback, ModelCheckpoint):\n",
    "                if callback.monitor == 'val_loss':    \n",
    "                    callback.save(model, epoch, val_loss)\n",
    "                elif callback.monitor == 'val_acc':\n",
    "                    callback.save(model, epoch, val_acc)\n",
    "            if isinstance(callback, EarlyStopping):\n",
    "                if callback.monitor == 'val_loss':\n",
    "                    is_early_stopped = callback.check_early_stop(val_loss)\n",
    "                if callback.monitor == 'val_acc':\n",
    "                    is_early_stopped = callback.check_early_stop(val_acc)\n",
    "                \n",
    "        return is_early_stopped\n",
    "\n",
    "    # 학습이 완료된 모델을 return\n",
    "    def get_trained_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = create_resnet_model('resnet50', num_classes=2, weights='DEFAULT')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001) # model.fc.parameters(), weight_decay=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# scheduler 사용하지 않음.  \n",
    "# scheduler = ReduceLROnPlateau(\n",
    "#             optimizer=optimizer, mode='min', factor=0.5, patience=5, threshold=0.01, min_lr=0.00001)\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint('checkpoints', monitor='val_acc', mode='max', save_interval=1, verbose=1)\n",
    "#checkpoint_cb = ModelCheckpoint('checkpoints', monitor='val_loss', mode='min', save_interval=1, verbose=1)\n",
    "earlystop_cb = EarlyStopping(monitor='val_acc', mode='max', early_patience=5, verbose=1)\n",
    "#earlystop_cb = EarlyStopping(monitor='val_loss', mode='min', early_patience=5, verbose=1)\n",
    "\n",
    "# ModelCheckpoint와 EarlyStopping 클래스를 list의 요소를 입력. \n",
    "callbacks = [checkpoint_cb, earlystop_cb] # None\n",
    "trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "                  train_loader=tr_loader, val_loader=val_loader, scheduler=None, \n",
    "                  callbacks=callbacks,\n",
    "                  device=device)\n",
    "# 학습 및 평가. \n",
    "history = trainer.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trained_model = trainer.get_trained_model()\n",
    "\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls -lrt /kaggle/working/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('/kaggle/working/checkpoints/checkpoint_epoch_10_val_acc_0.9300.pt', weights_only=True)\n",
    "\n",
    "# Pretrained Weight가 없는 모델로 생성. \n",
    "new_model = create_resnet_model('resnet50', num_classes=2, weights=None)\n",
    "# 신규 모델에 checkpoint 저장된 파라미터 로딩\n",
    "new_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(model=new_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 23777,
     "sourceId": 30378,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
