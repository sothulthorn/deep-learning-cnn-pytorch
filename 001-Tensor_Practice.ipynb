{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tensor 생성, shape, 차원, 타입\n",
    "* torch Tensor는 scalar값, python list, numpy array, 기존 tensor등을 기반으로 생성할 수 있음.\n",
    "* tensor의 형태(shape)는 shape 속성 또는 size() 메소드로 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01: torch.Size([3]) ts_02 shape: torch.Size([2, 3]) ts_03 shape: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "list_01 = [1, 2, 3]\n",
    "ts_01 = torch.tensor(list_01)\n",
    "ts_02 = torch.tensor([[1, 2, 3],\n",
    "                      [2, 3, 4]\n",
    "                     ])\n",
    "ts_03 = torch.tensor([\n",
    "                      [[1, 2, 3],\n",
    "                       [2, 3, 4]],\n",
    "                      [[3, 4, 5],\n",
    "                       [4, 5, 6]]\n",
    "                     ]) \n",
    "print('ts_01:', ts_01.shape, 'ts_02 shape:', ts_02.shape, 'ts_03 shape:', ts_03.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor의 shape/size 및 차원\n",
    "* pytorch tensor는 shape 속성 및 size() 메소드를 통해 torch.Size 오브젝트를 반환하여 tensor의 형태(shape)를 제공\n",
    "* shape 속성과 size() 메소드는 거의 동일.\n",
    "* 순수하게 차원 정보만 알고 싶을 때는 ndim 속성을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ts_02.shape, ts_02.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 2 3 2\n"
     ]
    }
   ],
   "source": [
    "print(ts_02.shape[0], ts_02.shape[1], ts_02.size(0), ts_02.size(1), ts_02.size()[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_02.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor 데이터 타입\n",
    "* tensor내의 값은 동일한 데이터 타입을 가짐. dtype 속성으로 확인\n",
    "* 데이터 타입은 생성시에 지정하거나, type() 또는 to() 메소드를 이용하여 변환. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.tensor([1.0, 2, 3])\n",
    "print(ts_01.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(ts_01.dtype)  # torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "ts_01_1 = ts_01.int() #int32로 변환\n",
    "print(ts_01_1.dtype)\n",
    "\n",
    "ts_01_2 = ts_01.float() #float32 변환\n",
    "print(ts_01_2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int8\n"
     ]
    }
   ],
   "source": [
    "ts_01_1 = ts_01.type(torch.int64)\n",
    "print(ts_01_1.dtype)\n",
    "\n",
    "ts_01_2 = ts_01.type(torch.int8) # float32/float64\n",
    "print(ts_01_2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int8\n"
     ]
    }
   ],
   "source": [
    "ts_01_1 = ts_01.to(torch.int64)\n",
    "print(ts_01_1.dtype)\n",
    "\n",
    "ts_01_2 = ts_01.to(torch.int8) # float32/float64\n",
    "print(ts_01_2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy array와 pytorch tensor간 상호 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> tensor([1, 2]) tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# numpy array를 tensor로 변환. \n",
    "arr_01 = np.array([1, 2])\n",
    "ts_01 = torch.tensor(arr_01)\n",
    "ts_02 = torch.from_numpy(arr_01)\n",
    "print(type(arr_01), ts_01, ts_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] <class 'numpy.ndarray'> [1, 2] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# tensor를 array 또는 list로 변환. \n",
    "arr_01_1 = ts_01.numpy()\n",
    "list_01 = ts_01.tolist()\n",
    "print(arr_01_1, type(arr_01_1), list_01, type(list_01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "ts_01 = torch.tensor([1, 2])\n",
    "ts_01_1 = ts_01.to('cpu')\n",
    "# ts_01_1 = ts_01.to('cuda')\n",
    "# 아래는 오류를 발생. device가 cuda에 있는 tensor의 경우 numpy() 메소드를 바로 호출 할 수 없음.\n",
    "arr_01_1 = ts_01_1.numpy() #  ts_01_1.cpu().numpy()를 호출해야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_01: [1 2] ts_01: tensor([1, 2])\n",
      "arr_01: [0 2] ts_01: tensor([0, 2])\n",
      "arr_01: [100   2] ts_01: tensor([100,   2]) ts_02: tensor([0, 2])\n"
     ]
    }
   ],
   "source": [
    "# tensor.from_numpy(array) 수행 시 생성된 tensor는 입력된 array와 메모리를 공유\n",
    "# 입력 array가 변경될 경우 tensor도 같이 변경됨.\n",
    "arr_01 = np.array([1, 2])\n",
    "ts_01 = torch.from_numpy(arr_01)\n",
    "print('arr_01:', arr_01, 'ts_01:', ts_01)\n",
    "\n",
    "arr_01[0] = 0\n",
    "print('arr_01:', arr_01, 'ts_01:', ts_01)\n",
    "\n",
    "# clone() 을 사용하여 tensor를 복제\n",
    "ts_02 = ts_01.clone()\n",
    "arr_01[0] = 100\n",
    "print('arr_01:', arr_01, 'ts_01:', ts_01, 'ts_02:', ts_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor를 편리하게 생성하기 - arange, zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.int64 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "seq_ts = torch.arange(10)\n",
    "print(seq_ts)\n",
    "print(seq_ts.dtype, seq_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=(3, 2), dtype=torch.int32).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]], dtype=torch.int32)\n",
      "torch.int32 torch.Size([3, 2])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n",
      "torch.int16 torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "zero_ts = torch.zeros(size=(3, 2), dtype=torch.int32)  #문자열 'int32'는 안됨. \n",
    "print(zero_ts)\n",
    "print(zero_ts.dtype, zero_ts.shape)\n",
    "\n",
    "one_ts = torch.ones(3, 2, dtype=torch.int16) # tuple을 사용하지 않아도 됨\n",
    "print(one_ts)\n",
    "print(one_ts.dtype, one_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random 값 생성하기\n",
    "* rand()은 기본으로 0 ~ 1(1은 제외)사이의 균일 분포(uniform distribution) random 값을 생성.\n",
    "* randint()는 random 정수값을 생성\n",
    "* randn()은 정규 분포(Normal distribution) random 값을 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01:\n",
      " tensor([[0.6850, 0.9355, 0.2900, 0.3991],\n",
      "        [0.7470, 0.0215, 0.0654, 0.7855],\n",
      "        [0.3883, 0.6340, 0.9447, 0.4773]]) torch.float32\n",
      "tensor(0.0215) tensor(0.9447)\n",
      "ts_01:\n",
      " tensor([[61, 66, 46, 45],\n",
      "        [56,  1, 35,  1],\n",
      "        [23, 48, 88, 88]]) torch.int64\n",
      "tensor(1) tensor(88)\n",
      "ts_01:\n",
      " tensor([[-1.8030,  0.7348, -1.4956,  0.0521],\n",
      "        [ 1.1838,  1.6855, -0.3477, -0.3971],\n",
      "        [ 0.1480, -1.1127,  1.1575,  0.1298]]) torch.float32\n",
      "tensor(-1.8030) tensor(1.6855) tensor(-0.0054) tensor(1.1970)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)  # random 수행 시 마다 동일 값 생성을 위한 seed값 할당. \n",
    "\n",
    "ts_01 = torch.rand(size=(3, 4)) # 0 ~ 1 사이의 float32 random값. 1제외\n",
    "print('ts_01:\\n', ts_01, ts_01.dtype)\n",
    "print(ts_01.min(), ts_01.max())\n",
    "\n",
    "ts_01 = torch.randint(low=0, high=100, size=(3, 4)) # 0 ~ 99까지의 random value\n",
    "print('ts_01:\\n', ts_01, ts_01.dtype)\n",
    "print(ts_01.min(), ts_01.max())\n",
    "\n",
    "ts_01 = torch.randn(size=(3, 4)) # 평균이 0 이고, 분산이 1인 정규 분포 random value. \n",
    "print('ts_01:\\n', ts_01, ts_01.dtype)\n",
    "print(ts_01.min(), ts_01.max(), ts_01.mean(), ts_01.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor의 형태(shape)를 변경하는 reshape()와 view()\n",
    "* reshape()와 view() 모두 tensor의 형태를 변환하나 view()는 contiguous memory 구조에서만 동작됨.\n",
    "* pytorch는 reshape()보다는 view() 호출을 권장. (강제로) tensor에서 contiguous memory 구조를 유지하기를 권장함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01:\n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "ts_02:\n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "ts_03:\n",
      " tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "ts_01 = torch.arange(10)\n",
    "print('ts_01:\\n', ts_01)\n",
    "\n",
    "ts_02 = ts_01.reshape((2, 5))\n",
    "print('ts_02:\\n',ts_02)\n",
    "\n",
    "ts_03 = ts_01.reshape(5, 2)\n",
    "print('ts_03:\\n',ts_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 4]' is invalid for input of size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### 아래는 오류 발생 \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mts_01\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[3, 4]' is invalid for input of size 10"
     ]
    }
   ],
   "source": [
    "### 아래는 오류 발생 \n",
    "ts_01.reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02:\n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]]) torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "ts_02 = ts_01.view((2, 5))\n",
    "print('ts_02:\\n', ts_02, ts_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3072])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025) \n",
    "\n",
    "ts_01 = torch.rand(size=(16, 3, 32, 32))\n",
    "ts_02 = ts_01.view(16, -1)\n",
    "print(ts_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "#기본적으로 tensor는 contiguous memory 구조로 생성됨. \n",
    "ts_01 = torch.arange(10)\n",
    "ts_02 = ts_01.view(2, -1)\n",
    "ts_03 = ts_01.reshape(2, -1)\n",
    "\n",
    "print(ts_01.is_contiguous(), ts_02.is_contiguous(), ts_03.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor의 차원 위치를 변경하여 재배열하는 permute(), t(), transpose()\n",
    "* permute()는 차원의 위치를 자유롭게 변경할 수 있음.\n",
    "* t()는 2차원 tensor의 row와 col을 변경.\n",
    "* transpose()는 2개 차원의 위치만 변경할 수 있음.\n",
    "* permute(), t(), transpose() 수행 시 contiguous memory가 구조가 깨지므로 view() 적용 시 유의 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[6.8497e-01, 9.3553e-01, 2.9004e-01],\n",
      "         [3.9910e-01, 7.4704e-01, 2.1453e-02],\n",
      "         [6.5449e-02, 7.8547e-01, 3.8830e-01],\n",
      "         ...,\n",
      "         [5.7394e-01, 6.7899e-01, 1.4175e-01],\n",
      "         [1.0564e-01, 6.2005e-02, 5.4586e-01],\n",
      "         [5.5911e-01, 9.6809e-01, 9.7254e-02]],\n",
      "\n",
      "        [[9.9808e-01, 6.6539e-01, 8.2797e-02],\n",
      "         [5.1192e-01, 6.0581e-01, 4.7461e-01],\n",
      "         [4.6758e-01, 7.2692e-01, 6.9974e-01],\n",
      "         ...,\n",
      "         [8.4161e-02, 1.8078e-01, 6.4848e-01],\n",
      "         [4.9513e-01, 1.9589e-01, 9.0705e-01],\n",
      "         [8.4488e-01, 6.6279e-01, 9.3101e-01]],\n",
      "\n",
      "        [[8.8574e-01, 9.4726e-01, 8.8349e-02],\n",
      "         [2.6516e-01, 5.0015e-02, 1.8065e-01],\n",
      "         [2.7291e-01, 5.1031e-01, 7.9525e-01],\n",
      "         ...,\n",
      "         [6.8054e-01, 6.4050e-01, 5.4171e-01],\n",
      "         [3.6098e-01, 8.0259e-01, 9.6788e-01],\n",
      "         [6.9853e-01, 1.8310e-01, 9.5629e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[6.2225e-01, 5.3005e-01, 6.3497e-01],\n",
      "         [5.0247e-01, 9.5379e-02, 4.5555e-03],\n",
      "         [5.8358e-01, 1.8659e-02, 7.6283e-02],\n",
      "         ...,\n",
      "         [3.2243e-01, 3.9305e-02, 1.0567e-01],\n",
      "         [7.1531e-01, 3.1300e-01, 4.1380e-02],\n",
      "         [6.6878e-01, 2.5928e-04, 4.2020e-01]],\n",
      "\n",
      "        [[6.6052e-01, 1.0501e-01, 7.3086e-01],\n",
      "         [2.3197e-01, 9.0479e-01, 7.1522e-02],\n",
      "         [3.0470e-01, 1.2098e-01, 2.3513e-01],\n",
      "         ...,\n",
      "         [7.2507e-01, 4.6751e-01, 7.1717e-01],\n",
      "         [1.6413e-01, 9.7555e-01, 9.7776e-01],\n",
      "         [1.0215e-01, 1.8344e-02, 3.7663e-01]],\n",
      "\n",
      "        [[4.6501e-01, 6.7409e-01, 8.0766e-01],\n",
      "         [7.8753e-01, 6.8398e-02, 9.2658e-02],\n",
      "         [4.7813e-01, 7.5199e-02, 2.9097e-01],\n",
      "         ...,\n",
      "         [6.4658e-01, 2.3335e-02, 4.5771e-01],\n",
      "         [1.1923e-01, 6.7086e-02, 2.3070e-01],\n",
      "         [6.2869e-01, 8.6278e-01, 9.4428e-01]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "ts_01 = torch.rand(size=(64, 64, 3))\n",
    "print(ts_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 3])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "ts_01 = torch.rand(size=(64, 64, 3))\n",
    "print(ts_01.shape)\n",
    "\n",
    "ts_02 = ts_01.permute(dims=(2, 0, 1)) # torch.permute(ts_01, dims=(2, 0, 1))\n",
    "print(ts_02.shape)\n",
    "\n",
    "ts_03 = ts_02.permute(dims=(1, 2, 0)) # torch.permute(ts_02, dims=(1, 2, 0))\n",
    "print(ts_03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(16, 32, 32, 3))\n",
    "ts_02 = ts_01.permute(dims=(0, 3, 1, 2))\n",
    "print(ts_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02 shape: torch.Size([64, 64, 3])\n",
      "is ts_02 contiguous?  False\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(3, 64, 64))\n",
    "ts_02 = torch.permute(ts_01, dims=(1, 2, 0)) #permute로 차원 이동 시 연속(contiguous) 메모리 구조가 깨질 수 있음.\n",
    "print('ts_02 shape:', ts_02.shape)\n",
    "print('is ts_02 contiguous? ', ts_02.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ts_02_1 = \u001b[43mts_02\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# permute로 차원 이동 시 연속(contiguous) 메모리 구조가 깨질 수 있음. 이 경우 view를 사용하면 안됨.\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "ts_02_1 = ts_02.view(64, -1)# permute로 차원 이동 시 연속(contiguous) 메모리 구조가 깨질 수 있음. 이 경우 view를 사용하면 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02_1 shape: torch.Size([64, 192])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(3, 64, 64))\n",
    "ts_02 = torch.permute(ts_01, dims=(1, 2, 0))\n",
    "\n",
    "ts_02_1 = ts_02.reshape(64, -1) # reshape는 연속 메모리 구조와 관계없이 변환\n",
    "print('ts_02_1 shape:', ts_02_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02 shape: torch.Size([64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(3, 64, 64))\n",
    "ts_02 = torch.permute(ts_01, dims=(1, 2, 0))\n",
    "print('ts_02 shape:', ts_02.shape)\n",
    "\n",
    "ts_02_1 = ts_02.contiguous().view(64, -1) # contiguous()로 연속 메모리 구조 만든 후 view() 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02 shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(3, 4))\n",
    "ts_02 = ts_01.t()\n",
    "print('ts_02 shape:', ts_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_02 shape: torch.Size([64, 3, 248, 128])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.rand(size=(64, 3, 128, 248))\n",
    "ts_02 = ts_01.transpose(2, 3)\n",
    "print('ts_02 shape:', ts_02.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor에 sum, max, min, mean등의 aggregation 적용\n",
    "* sum, max, min, mean등의 aggregation 메소드는 dim 인자를 가짐. dim이 None일 경우 전체 원소들에 aggregation 적용.\n",
    "* dim인자는 해당 차원(axis 축)을 따라서(방향성으로) aggregation을 수행.\n",
    "* 단일 차원의 dim인자를 적용하여 aggregation을 수행 할 경우 반환되는 tensor의 차원수는 원본 tensor의 차원 수 - 1임.\n",
    "* 여러 차원의 dim인자를 적용하여 aggregation을 수행 할 경우 반환되는 tensor의 차원수는 원본 tensor의 차원 수 - 해당 dim 차원수임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_01 = torch.arange(10).view(2, 5)\n",
    "ts_01.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "total sum: tensor(45)\n",
      "sum along dim=0: tensor([ 5,  7,  9, 11, 13])\n",
      "sum along dim=1: tensor([10, 35])\n",
      "max overall: tensor(9)\n",
      "max along dim=0: torch.return_types.max(\n",
      "values=tensor([5, 6, 7, 8, 9]),\n",
      "indices=tensor([1, 1, 1, 1, 1]))\n",
      "max along dim=1: torch.return_types.max(\n",
      "values=tensor([4, 9]),\n",
      "indices=tensor([4, 4]))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "ts_01 = torch.arange(10).view(2, 5)\n",
    "print(ts_01)\n",
    "\n",
    "print('total sum:', ts_01.sum())\n",
    "print('sum along dim=0:', ts_01.sum(dim=0))\n",
    "print('sum along dim=1:', ts_01.sum(dim=1))\n",
    "\n",
    "print('max overall:', ts_01.max())\n",
    "print('max along dim=0:', ts_01.max(dim=0))# max값과 max가 위치한 index값을 함께 반환. \n",
    "print('max along dim=1:', ts_01.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6335, 0.1099, 0.0149,  ..., 0.2430, 0.3917, 0.1999],\n",
      "          [0.1033, 0.2894, 0.7031,  ..., 0.0234, 0.6310, 0.7200],\n",
      "          [0.7143, 0.6883, 0.9132,  ..., 0.2962, 0.9564, 0.3480],\n",
      "          ...,\n",
      "          [0.6361, 0.8075, 0.7447,  ..., 0.7073, 0.0075, 0.9899],\n",
      "          [0.7209, 0.5302, 0.6207,  ..., 0.9144, 0.1500, 0.1958],\n",
      "          [0.7484, 0.8991, 0.0279,  ..., 0.5883, 0.0924, 0.0875]],\n",
      "\n",
      "         [[0.4549, 0.4800, 0.6778,  ..., 0.4058, 0.0507, 0.2481],\n",
      "          [0.5892, 0.3991, 0.9660,  ..., 0.2820, 0.0866, 0.3481],\n",
      "          [0.5252, 0.1388, 0.7346,  ..., 0.3005, 0.7434, 0.4079],\n",
      "          ...,\n",
      "          [0.9005, 0.9332, 0.2450,  ..., 0.3190, 0.5345, 0.8825],\n",
      "          [0.6825, 0.3160, 0.9577,  ..., 0.6890, 0.4037, 0.7594],\n",
      "          [0.7855, 0.4750, 0.0240,  ..., 0.4860, 0.9674, 0.7318]],\n",
      "\n",
      "         [[0.4826, 0.4516, 0.5195,  ..., 0.9992, 0.7352, 0.1057],\n",
      "          [0.4194, 0.7260, 0.4793,  ..., 0.9997, 0.7695, 0.0804],\n",
      "          [0.7762, 0.7646, 0.7574,  ..., 0.1611, 0.5650, 0.7535],\n",
      "          ...,\n",
      "          [0.1488, 0.9126, 0.2492,  ..., 0.3933, 0.9024, 0.9484],\n",
      "          [0.2102, 0.5562, 0.4890,  ..., 0.1943, 0.5678, 0.3142],\n",
      "          [0.8570, 0.9401, 0.7596,  ..., 0.3870, 0.3177, 0.6961]]],\n",
      "\n",
      "\n",
      "        [[[0.2690, 0.1593, 0.1114,  ..., 0.6594, 0.0804, 0.3319],\n",
      "          [0.5599, 0.3203, 0.2735,  ..., 0.7781, 0.7329, 0.8289],\n",
      "          [0.4388, 0.0639, 0.6499,  ..., 0.9873, 0.4538, 0.7739],\n",
      "          ...,\n",
      "          [0.4873, 0.2357, 0.1146,  ..., 0.1258, 0.2603, 0.0922],\n",
      "          [0.5853, 0.5382, 0.1736,  ..., 0.6621, 0.9354, 0.5900],\n",
      "          [0.9992, 0.8155, 0.5350,  ..., 0.8230, 0.9796, 0.9954]],\n",
      "\n",
      "         [[0.1830, 0.7183, 0.6635,  ..., 0.2340, 0.9054, 0.9618],\n",
      "          [0.2075, 0.9690, 0.5257,  ..., 0.6290, 0.4606, 0.1132],\n",
      "          [0.7587, 0.0844, 0.6666,  ..., 0.1501, 0.2534, 0.1530],\n",
      "          ...,\n",
      "          [0.9836, 0.6162, 0.9971,  ..., 0.8728, 0.9732, 0.4153],\n",
      "          [0.7693, 0.3540, 0.5681,  ..., 0.2646, 0.9530, 0.0930],\n",
      "          [0.9561, 0.7923, 0.0840,  ..., 0.0095, 0.7216, 0.2306]],\n",
      "\n",
      "         [[0.0542, 0.6234, 0.3431,  ..., 0.2291, 0.6768, 0.7954],\n",
      "          [0.5406, 0.1143, 0.3364,  ..., 0.7245, 0.5779, 0.2852],\n",
      "          [0.8460, 0.5270, 0.9304,  ..., 0.8085, 0.5954, 0.0560],\n",
      "          ...,\n",
      "          [0.2019, 0.9944, 0.8396,  ..., 0.7633, 0.4480, 0.3554],\n",
      "          [0.0646, 0.1990, 0.0779,  ..., 0.4077, 0.3464, 0.5471],\n",
      "          [0.6592, 0.9256, 0.3128,  ..., 0.6558, 0.3750, 0.3538]]],\n",
      "\n",
      "\n",
      "        [[[0.2534, 0.6669, 0.3023,  ..., 0.0513, 0.3212, 0.2490],\n",
      "          [0.2051, 0.0541, 0.9704,  ..., 0.1629, 0.6456, 0.4867],\n",
      "          [0.9194, 0.0424, 0.2209,  ..., 0.2784, 0.8826, 0.4418],\n",
      "          ...,\n",
      "          [0.3913, 0.7970, 0.6387,  ..., 0.6433, 0.7216, 0.6229],\n",
      "          [0.5432, 0.6256, 0.4977,  ..., 0.8687, 0.8455, 0.8029],\n",
      "          [0.5601, 0.5847, 0.0095,  ..., 0.6127, 0.5872, 0.7755]],\n",
      "\n",
      "         [[0.1081, 0.0060, 0.9954,  ..., 0.9084, 0.5680, 0.1116],\n",
      "          [0.9805, 0.5583, 0.0220,  ..., 0.3181, 0.0149, 0.4457],\n",
      "          [0.7799, 0.0752, 0.3186,  ..., 0.1662, 0.9503, 0.4698],\n",
      "          ...,\n",
      "          [0.3529, 0.4728, 0.1739,  ..., 0.0777, 0.4062, 0.1691],\n",
      "          [0.3127, 0.6087, 0.8179,  ..., 0.9081, 0.2500, 0.6083],\n",
      "          [0.5961, 0.1558, 0.4875,  ..., 0.5050, 0.6404, 0.5530]],\n",
      "\n",
      "         [[0.9322, 0.7130, 0.6032,  ..., 0.6165, 0.3097, 0.7251],\n",
      "          [0.4779, 0.9100, 0.0071,  ..., 0.1650, 0.8970, 0.0579],\n",
      "          [0.7167, 0.2556, 0.1287,  ..., 0.7833, 0.7577, 0.0617],\n",
      "          ...,\n",
      "          [0.2820, 0.0162, 0.1007,  ..., 0.9958, 0.6454, 0.1079],\n",
      "          [0.8299, 0.7800, 0.9602,  ..., 0.9631, 0.2538, 0.6030],\n",
      "          [0.4055, 0.2509, 0.7197,  ..., 0.7173, 0.2831, 0.2499]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3983, 0.9958, 0.8631,  ..., 0.6150, 0.1597, 0.6593],\n",
      "          [0.8570, 0.1088, 0.3330,  ..., 0.3877, 0.7680, 0.0245],\n",
      "          [0.6139, 0.2065, 0.7574,  ..., 0.3088, 0.5623, 0.4098],\n",
      "          ...,\n",
      "          [0.2080, 0.8573, 0.2331,  ..., 0.1561, 0.3286, 0.7309],\n",
      "          [0.8910, 0.4835, 0.0940,  ..., 0.2934, 0.1084, 0.3004],\n",
      "          [0.4105, 0.2834, 0.8754,  ..., 0.4648, 0.3574, 0.2281]],\n",
      "\n",
      "         [[0.2087, 0.7713, 0.0608,  ..., 0.7689, 0.7504, 0.1181],\n",
      "          [0.2993, 0.2135, 0.8991,  ..., 0.8182, 0.8722, 0.2430],\n",
      "          [0.5357, 0.3753, 0.0666,  ..., 0.2900, 0.7342, 0.4014],\n",
      "          ...,\n",
      "          [0.4957, 0.5938, 0.8044,  ..., 0.6908, 0.6886, 0.2070],\n",
      "          [0.4683, 0.3296, 0.5334,  ..., 0.2768, 0.1985, 0.7775],\n",
      "          [0.7429, 0.4022, 0.8598,  ..., 0.4604, 0.7156, 0.1271]],\n",
      "\n",
      "         [[0.0654, 0.3867, 0.5190,  ..., 0.4104, 0.7060, 0.6499],\n",
      "          [0.5455, 0.2380, 0.0303,  ..., 0.4393, 0.3219, 0.1594],\n",
      "          [0.2080, 0.7023, 0.7792,  ..., 0.3808, 0.6131, 0.1311],\n",
      "          ...,\n",
      "          [0.3880, 0.7605, 0.6743,  ..., 0.9612, 0.6706, 0.0199],\n",
      "          [0.6784, 0.4735, 0.1481,  ..., 0.1415, 0.7984, 0.6862],\n",
      "          [0.1558, 0.7536, 0.4362,  ..., 0.6158, 0.9130, 0.0403]]],\n",
      "\n",
      "\n",
      "        [[[0.3054, 0.0452, 0.4823,  ..., 0.7453, 0.8050, 0.8522],\n",
      "          [0.5444, 0.6381, 0.8120,  ..., 0.0044, 0.5791, 0.9087],\n",
      "          [0.4579, 0.5845, 0.0413,  ..., 0.6348, 0.6808, 0.7867],\n",
      "          ...,\n",
      "          [0.1340, 0.4407, 0.3271,  ..., 0.8999, 0.7142, 0.5279],\n",
      "          [0.7905, 0.9901, 0.6498,  ..., 0.3924, 0.8573, 0.6682],\n",
      "          [0.1301, 0.3649, 0.7518,  ..., 0.1583, 0.7519, 0.0868]],\n",
      "\n",
      "         [[0.1610, 0.8243, 0.9293,  ..., 0.1453, 0.8194, 0.2713],\n",
      "          [0.5022, 0.6092, 0.6024,  ..., 0.1757, 0.7436, 0.6410],\n",
      "          [0.0662, 0.1081, 0.4586,  ..., 0.7554, 0.4396, 0.7050],\n",
      "          ...,\n",
      "          [0.5773, 0.4907, 0.5661,  ..., 0.4428, 0.5934, 0.1989],\n",
      "          [0.9678, 0.5852, 0.9545,  ..., 0.8998, 0.4298, 0.4997],\n",
      "          [0.1172, 0.3364, 0.2885,  ..., 0.8796, 0.5056, 0.5932]],\n",
      "\n",
      "         [[0.0053, 0.3246, 0.8182,  ..., 0.4331, 0.3876, 0.3238],\n",
      "          [0.9612, 0.9921, 0.0637,  ..., 0.5549, 0.3287, 0.9039],\n",
      "          [0.1903, 0.6224, 0.7195,  ..., 0.8780, 0.3050, 0.8222],\n",
      "          ...,\n",
      "          [0.6835, 0.9776, 0.7307,  ..., 0.9753, 0.8009, 0.8008],\n",
      "          [0.8597, 0.5140, 0.7567,  ..., 0.6252, 0.0811, 0.9299],\n",
      "          [0.2332, 0.9869, 0.4530,  ..., 0.0942, 0.3735, 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[0.8363, 0.8140, 0.6992,  ..., 0.6200, 0.7439, 0.9798],\n",
      "          [0.1622, 0.9082, 0.9423,  ..., 0.2590, 0.3648, 0.1891],\n",
      "          [0.4966, 0.2976, 0.4684,  ..., 0.4710, 0.6993, 0.7088],\n",
      "          ...,\n",
      "          [0.2179, 0.1771, 0.2675,  ..., 0.0305, 0.4154, 0.9199],\n",
      "          [0.0289, 0.8589, 0.1513,  ..., 0.2944, 0.2860, 0.3955],\n",
      "          [0.3100, 0.9859, 0.3517,  ..., 0.8788, 0.1775, 0.0842]],\n",
      "\n",
      "         [[0.8777, 0.0430, 0.7156,  ..., 0.1601, 0.3539, 0.5346],\n",
      "          [0.9472, 0.9808, 0.3345,  ..., 0.1101, 0.5745, 0.9478],\n",
      "          [0.9672, 0.7580, 0.4531,  ..., 0.0610, 0.9575, 0.2048],\n",
      "          ...,\n",
      "          [0.1998, 0.4896, 0.8965,  ..., 0.9458, 0.1116, 0.8728],\n",
      "          [0.3017, 0.8631, 0.4689,  ..., 0.4390, 0.2710, 0.3881],\n",
      "          [0.7945, 0.9156, 0.6142,  ..., 0.0099, 0.1839, 0.9655]],\n",
      "\n",
      "         [[0.1001, 0.4953, 0.6864,  ..., 0.3346, 0.0190, 0.8647],\n",
      "          [0.5686, 0.4745, 0.3328,  ..., 0.3168, 0.0075, 0.2862],\n",
      "          [0.8464, 0.5410, 0.1810,  ..., 0.7861, 0.2528, 0.8028],\n",
      "          ...,\n",
      "          [0.9143, 0.2233, 0.0267,  ..., 0.1313, 0.8899, 0.3224],\n",
      "          [0.4336, 0.7405, 0.6452,  ..., 0.1394, 0.8349, 0.2142],\n",
      "          [0.5918, 0.3979, 0.3917,  ..., 0.8671, 0.2635, 0.8016]]]])\n",
      "overall mean: tensor(0.4999, dtype=torch.float64)\n",
      "mean along dim=0: tensor([[[0.5059, 0.5351, 0.5182,  ..., 0.4501, 0.5351, 0.4914],\n",
      "         [0.5053, 0.5064, 0.5111,  ..., 0.4572, 0.4034, 0.5501],\n",
      "         [0.4966, 0.4895, 0.4418,  ..., 0.4995, 0.4580, 0.5314],\n",
      "         ...,\n",
      "         [0.5002, 0.5785, 0.5439,  ..., 0.4923, 0.5562, 0.4749],\n",
      "         [0.4696, 0.4865, 0.5237,  ..., 0.5092, 0.5085, 0.4729],\n",
      "         [0.5525, 0.5046, 0.5046,  ..., 0.5182, 0.5391, 0.4602]],\n",
      "\n",
      "        [[0.5040, 0.4905, 0.5291,  ..., 0.4353, 0.4880, 0.5358],\n",
      "         [0.4853, 0.5666, 0.4667,  ..., 0.4570, 0.4655, 0.4840],\n",
      "         [0.5260, 0.4688, 0.5147,  ..., 0.4779, 0.5806, 0.5605],\n",
      "         ...,\n",
      "         [0.5464, 0.5759, 0.4572,  ..., 0.5133, 0.4720, 0.5684],\n",
      "         [0.4967, 0.5204, 0.4956,  ..., 0.5076, 0.5218, 0.4872],\n",
      "         [0.4459, 0.5029, 0.4548,  ..., 0.4411, 0.4709, 0.4920]],\n",
      "\n",
      "        [[0.5521, 0.5727, 0.4311,  ..., 0.4371, 0.5320, 0.4633],\n",
      "         [0.4730, 0.4391, 0.5380,  ..., 0.5230, 0.5412, 0.4526],\n",
      "         [0.5187, 0.5633, 0.5324,  ..., 0.6065, 0.5267, 0.4667],\n",
      "         ...,\n",
      "         [0.4886, 0.4725, 0.4885,  ..., 0.4491, 0.5067, 0.4923],\n",
      "         [0.5614, 0.4860, 0.5665,  ..., 0.5264, 0.5182, 0.5063],\n",
      "         [0.5408, 0.5407, 0.5120,  ..., 0.4932, 0.4791, 0.4436]]],\n",
      "       dtype=torch.float64)\n",
      "mean along dim=1: tensor([[[0.5237, 0.3471, 0.4041,  ..., 0.5493, 0.3925, 0.1845],\n",
      "         [0.3706, 0.4715, 0.7162,  ..., 0.4350, 0.4957, 0.3828],\n",
      "         [0.6719, 0.5306, 0.8017,  ..., 0.2526, 0.7549, 0.5031],\n",
      "         ...,\n",
      "         [0.5618, 0.8845, 0.4130,  ..., 0.4732, 0.4814, 0.9402],\n",
      "         [0.5379, 0.4675, 0.6891,  ..., 0.5992, 0.3739, 0.4231],\n",
      "         [0.7970, 0.7714, 0.2705,  ..., 0.4871, 0.4592, 0.5051]],\n",
      "\n",
      "        [[0.1688, 0.5003, 0.3727,  ..., 0.3741, 0.5542, 0.6964],\n",
      "         [0.4360, 0.4679, 0.3785,  ..., 0.7105, 0.5905, 0.4091],\n",
      "         [0.6812, 0.2251, 0.7489,  ..., 0.6486, 0.4342, 0.3276],\n",
      "         ...,\n",
      "         [0.5576, 0.6154, 0.6504,  ..., 0.5873, 0.5605, 0.2876],\n",
      "         [0.4731, 0.3637, 0.2732,  ..., 0.4448, 0.7449, 0.4100],\n",
      "         [0.8715, 0.8444, 0.3106,  ..., 0.4961, 0.6921, 0.5266]],\n",
      "\n",
      "        [[0.4312, 0.4620, 0.6336,  ..., 0.5254, 0.3996, 0.3619],\n",
      "         [0.5545, 0.5075, 0.3332,  ..., 0.2153, 0.5192, 0.3301],\n",
      "         [0.8053, 0.1244, 0.2227,  ..., 0.4093, 0.8635, 0.3244],\n",
      "         ...,\n",
      "         [0.3421, 0.4287, 0.3045,  ..., 0.5723, 0.5911, 0.3000],\n",
      "         [0.5619, 0.6714, 0.7586,  ..., 0.9133, 0.4498, 0.6714],\n",
      "         [0.5206, 0.3305, 0.4055,  ..., 0.6117, 0.5036, 0.5261]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2242, 0.7179, 0.4810,  ..., 0.5981, 0.5387, 0.4757],\n",
      "         [0.5672, 0.1868, 0.4208,  ..., 0.5484, 0.6540, 0.1423],\n",
      "         [0.4526, 0.4280, 0.5344,  ..., 0.3265, 0.6365, 0.3141],\n",
      "         ...,\n",
      "         [0.3639, 0.7372, 0.5706,  ..., 0.6027, 0.5626, 0.3193],\n",
      "         [0.6792, 0.4289, 0.2585,  ..., 0.2372, 0.3684, 0.5880],\n",
      "         [0.4364, 0.4798, 0.7238,  ..., 0.5137, 0.6620, 0.1318]],\n",
      "\n",
      "        [[0.1572, 0.3980, 0.7433,  ..., 0.4412, 0.6707, 0.4824],\n",
      "         [0.6692, 0.7465, 0.4927,  ..., 0.2450, 0.5505, 0.8179],\n",
      "         [0.2381, 0.4383, 0.4065,  ..., 0.7561, 0.4751, 0.7713],\n",
      "         ...,\n",
      "         [0.4649, 0.6363, 0.5413,  ..., 0.7727, 0.7028, 0.5092],\n",
      "         [0.8727, 0.6964, 0.7870,  ..., 0.6391, 0.4561, 0.6993],\n",
      "         [0.1602, 0.5627, 0.4978,  ..., 0.3774, 0.5437, 0.2280]],\n",
      "\n",
      "        [[0.6047, 0.4508, 0.7004,  ..., 0.3716, 0.3722, 0.7930],\n",
      "         [0.5593, 0.7878, 0.5366,  ..., 0.2286, 0.3156, 0.4743],\n",
      "         [0.7700, 0.5322, 0.3675,  ..., 0.4393, 0.6366, 0.5721],\n",
      "         ...,\n",
      "         [0.4440, 0.2967, 0.3969,  ..., 0.3692, 0.4723, 0.7050],\n",
      "         [0.2547, 0.8208, 0.4218,  ..., 0.2909, 0.4640, 0.3326],\n",
      "         [0.5654, 0.7665, 0.4525,  ..., 0.5853, 0.2083, 0.6171]]],\n",
      "       dtype=torch.float64)\n",
      "min overall: tensor(5.9605e-08)\n",
      "min along dim=0: torch.return_types.min(\n",
      "values=tensor([[[0.0243, 0.0098, 0.0054,  ..., 0.0017, 0.0619, 0.0052],\n",
      "         [0.0353, 0.0016, 0.0031,  ..., 0.0044, 0.0054, 0.0245],\n",
      "         [0.0500, 0.0050, 0.0092,  ..., 0.0541, 0.0074, 0.0156],\n",
      "         ...,\n",
      "         [0.0142, 0.0458, 0.0386,  ..., 0.0305, 0.0075, 0.0205],\n",
      "         [0.0020, 0.0105, 0.0631,  ..., 0.0033, 0.0007, 0.0004],\n",
      "         [0.0065, 0.0038, 0.0012,  ..., 0.0277, 0.0064, 0.0038]],\n",
      "\n",
      "        [[0.0187, 0.0045, 0.0348,  ..., 0.0004, 0.0114, 0.0433],\n",
      "         [0.0041, 0.0928, 0.0146,  ..., 0.0502, 0.0032, 0.0110],\n",
      "         [0.0101, 0.0023, 0.0381,  ..., 0.0311, 0.0286, 0.0202],\n",
      "         ...,\n",
      "         [0.0033, 0.0025, 0.0029,  ..., 0.0107, 0.0191, 0.0343],\n",
      "         [0.0178, 0.0122, 0.0047,  ..., 0.0066, 0.0162, 0.0049],\n",
      "         [0.0020, 0.0128, 0.0002,  ..., 0.0095, 0.0009, 0.0354]],\n",
      "\n",
      "        [[0.0052, 0.0827, 0.0040,  ..., 0.0120, 0.0190, 0.0133],\n",
      "         [0.0025, 0.0136, 0.0065,  ..., 0.0094, 0.0075, 0.0142],\n",
      "         [0.0115, 0.0204, 0.0108,  ..., 0.0058, 0.0021, 0.0057],\n",
      "         ...,\n",
      "         [0.0288, 0.0018, 0.0042,  ..., 0.0036, 0.0011, 0.0199],\n",
      "         [0.0192, 0.0182, 0.0213,  ..., 0.0299, 0.0228, 0.0205],\n",
      "         [0.0149, 0.0360, 0.0163,  ..., 0.0177, 0.0157, 0.0039]]]),\n",
      "indices=tensor([[[ 3, 45, 33,  ..., 13, 54,  8],\n",
      "         [10, 23, 39,  ..., 62, 49, 61],\n",
      "         [53, 48, 11,  ..., 38, 38, 24],\n",
      "         ...,\n",
      "         [41, 54, 39,  ..., 63,  0, 40],\n",
      "         [36, 42, 57,  ..., 56, 45, 25],\n",
      "         [45, 43, 42,  ..., 23, 19, 29]],\n",
      "\n",
      "        [[42, 10, 12,  ..., 14, 45, 13],\n",
      "         [45, 31, 57,  ..., 46, 19, 12],\n",
      "         [38, 50, 30,  ..., 17, 17, 21],\n",
      "         ...,\n",
      "         [48, 46, 39,  ..., 38,  7, 52],\n",
      "         [28, 59, 59,  ..., 26, 19, 32],\n",
      "         [22, 32, 49,  ...,  1, 51, 29]],\n",
      "\n",
      "        [[ 3, 16,  8,  ..., 60, 63, 46],\n",
      "         [23, 51, 49,  ..., 24, 63, 30],\n",
      "         [ 5, 31, 28,  ..., 11, 15, 60],\n",
      "         ...,\n",
      "         [44, 31, 34,  ..., 35, 37, 61],\n",
      "         [15, 21, 20,  ..., 22, 24, 44],\n",
      "         [22, 39, 36,  ..., 15,  6, 62]]]))\n",
      "min along dim=1: torch.return_types.min(\n",
      "values=tensor([[[0.4549, 0.1099, 0.0149,  ..., 0.2430, 0.0507, 0.1057],\n",
      "         [0.1033, 0.2894, 0.4793,  ..., 0.0234, 0.0866, 0.0804],\n",
      "         [0.5252, 0.1388, 0.7346,  ..., 0.1611, 0.5650, 0.3480],\n",
      "         ...,\n",
      "         [0.1488, 0.8075, 0.2450,  ..., 0.3190, 0.0075, 0.8825],\n",
      "         [0.2102, 0.3160, 0.4890,  ..., 0.1943, 0.1500, 0.1958],\n",
      "         [0.7484, 0.4750, 0.0240,  ..., 0.3870, 0.0924, 0.0875]],\n",
      "\n",
      "        [[0.0542, 0.1593, 0.1114,  ..., 0.2291, 0.0804, 0.3319],\n",
      "         [0.2075, 0.1143, 0.2735,  ..., 0.6290, 0.4606, 0.1132],\n",
      "         [0.4388, 0.0639, 0.6499,  ..., 0.1501, 0.2534, 0.0560],\n",
      "         ...,\n",
      "         [0.2019, 0.2357, 0.1146,  ..., 0.1258, 0.2603, 0.0922],\n",
      "         [0.0646, 0.1990, 0.0779,  ..., 0.2646, 0.3464, 0.0930],\n",
      "         [0.6592, 0.7923, 0.0840,  ..., 0.0095, 0.3750, 0.2306]],\n",
      "\n",
      "        [[0.1081, 0.0060, 0.3023,  ..., 0.0513, 0.3097, 0.1116],\n",
      "         [0.2051, 0.0541, 0.0071,  ..., 0.1629, 0.0149, 0.0579],\n",
      "         [0.7167, 0.0424, 0.1287,  ..., 0.1662, 0.7577, 0.0617],\n",
      "         ...,\n",
      "         [0.2820, 0.0162, 0.1007,  ..., 0.0777, 0.4062, 0.1079],\n",
      "         [0.3127, 0.6087, 0.4977,  ..., 0.8687, 0.2500, 0.6030],\n",
      "         [0.4055, 0.1558, 0.0095,  ..., 0.5050, 0.2831, 0.2499]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0654, 0.3867, 0.0608,  ..., 0.4104, 0.1597, 0.1181],\n",
      "         [0.2993, 0.1088, 0.0303,  ..., 0.3877, 0.3219, 0.0245],\n",
      "         [0.2080, 0.2065, 0.0666,  ..., 0.2900, 0.5623, 0.1311],\n",
      "         ...,\n",
      "         [0.2080, 0.5938, 0.2331,  ..., 0.1561, 0.3286, 0.0199],\n",
      "         [0.4683, 0.3296, 0.0940,  ..., 0.1415, 0.1084, 0.3004],\n",
      "         [0.1558, 0.2834, 0.4362,  ..., 0.4604, 0.3574, 0.0403]],\n",
      "\n",
      "        [[0.0053, 0.0452, 0.4823,  ..., 0.1453, 0.3876, 0.2713],\n",
      "         [0.5022, 0.6092, 0.0637,  ..., 0.0044, 0.3287, 0.6410],\n",
      "         [0.0662, 0.1081, 0.0413,  ..., 0.6348, 0.3050, 0.7050],\n",
      "         ...,\n",
      "         [0.1340, 0.4407, 0.3271,  ..., 0.4428, 0.5934, 0.1989],\n",
      "         [0.7905, 0.5140, 0.6498,  ..., 0.3924, 0.0811, 0.4997],\n",
      "         [0.1172, 0.3364, 0.2885,  ..., 0.0942, 0.3735, 0.0039]],\n",
      "\n",
      "        [[0.1001, 0.0430, 0.6864,  ..., 0.1601, 0.0190, 0.5346],\n",
      "         [0.1622, 0.4745, 0.3328,  ..., 0.1101, 0.0075, 0.1891],\n",
      "         [0.4966, 0.2976, 0.1810,  ..., 0.0610, 0.2528, 0.2048],\n",
      "         ...,\n",
      "         [0.1998, 0.1771, 0.0267,  ..., 0.0305, 0.1116, 0.3224],\n",
      "         [0.0289, 0.7405, 0.1513,  ..., 0.1394, 0.2710, 0.2142],\n",
      "         [0.3100, 0.3979, 0.3517,  ..., 0.0099, 0.1775, 0.0842]]]),\n",
      "indices=tensor([[[1, 0, 0,  ..., 0, 1, 2],\n",
      "         [0, 0, 2,  ..., 0, 1, 2],\n",
      "         [1, 1, 1,  ..., 2, 2, 0],\n",
      "         ...,\n",
      "         [2, 0, 1,  ..., 1, 0, 1],\n",
      "         [2, 1, 2,  ..., 2, 0, 0],\n",
      "         [0, 1, 1,  ..., 2, 0, 0]],\n",
      "\n",
      "        [[2, 0, 0,  ..., 2, 0, 0],\n",
      "         [1, 2, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 2],\n",
      "         ...,\n",
      "         [2, 0, 0,  ..., 0, 0, 0],\n",
      "         [2, 2, 2,  ..., 1, 2, 1],\n",
      "         [2, 1, 1,  ..., 1, 2, 1]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 2, 1],\n",
      "         [0, 0, 2,  ..., 0, 1, 2],\n",
      "         [2, 0, 2,  ..., 1, 2, 2],\n",
      "         ...,\n",
      "         [2, 2, 2,  ..., 1, 1, 2],\n",
      "         [1, 1, 0,  ..., 0, 1, 2],\n",
      "         [2, 1, 0,  ..., 1, 2, 2]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2, 2, 1,  ..., 2, 0, 1],\n",
      "         [1, 0, 2,  ..., 0, 2, 0],\n",
      "         [2, 0, 1,  ..., 1, 0, 2],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 2],\n",
      "         [1, 1, 0,  ..., 2, 0, 0],\n",
      "         [2, 0, 2,  ..., 1, 0, 2]],\n",
      "\n",
      "        [[2, 0, 0,  ..., 1, 2, 1],\n",
      "         [1, 1, 2,  ..., 0, 2, 1],\n",
      "         [1, 1, 0,  ..., 0, 2, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 2, 0,  ..., 0, 2, 1],\n",
      "         [1, 1, 1,  ..., 2, 2, 2]],\n",
      "\n",
      "        [[2, 1, 2,  ..., 1, 2, 1],\n",
      "         [0, 2, 2,  ..., 1, 2, 0],\n",
      "         [0, 0, 2,  ..., 1, 2, 1],\n",
      "         ...,\n",
      "         [1, 0, 2,  ..., 0, 1, 2],\n",
      "         [0, 2, 0,  ..., 2, 1, 2],\n",
      "         [0, 2, 0,  ..., 1, 0, 0]]]))\n"
     ]
    }
   ],
   "source": [
    "print(ts_01)\n",
    "print('overall mean:', ts_01.mean(dtype=torch.float64))\n",
    "print('mean along dim=0:', ts_01.mean(dim=0, dtype=torch.float64))\n",
    "print('mean along dim=1:', ts_01.mean(dim=1, dtype=torch.float64))\n",
    "\n",
    "print('min overall:', ts_01.min())\n",
    "print('min along dim=0:', ts_01.min(dim=0))# min값과 min이 위치한 index값을 함께 반환. \n",
    "print('min along dim=1:', ts_01.min(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "total sum: tensor(276)\n",
      "sum along dim=0:\n",
      " tensor([[12, 14, 16, 18],\n",
      "        [20, 22, 24, 26],\n",
      "        [28, 30, 32, 34]])\n",
      "sum along dim=1:\n",
      " tensor([[12, 15, 18, 21],\n",
      "        [48, 51, 54, 57]])\n",
      "sum along dim=2:\n",
      " tensor([[ 6, 22, 38],\n",
      "        [54, 70, 86]])\n",
      "sum along dim=-1:\n",
      " tensor([[ 6, 22, 38],\n",
      "        [54, 70, 86]])\n",
      "max overall: tensor(23)\n",
      "max along dim=0: torch.return_types.max(\n",
      "values=tensor([[12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23]]),\n",
      "indices=tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]]))\n",
      "max along dim=1: torch.return_types.max(\n",
      "values=tensor([[ 8,  9, 10, 11],\n",
      "        [20, 21, 22, 23]]),\n",
      "indices=tensor([[2, 2, 2, 2],\n",
      "        [2, 2, 2, 2]]))\n"
     ]
    }
   ],
   "source": [
    "ts_02 = torch.arange(24).reshape(2, 3, 4)\n",
    "print(ts_02)\n",
    "\n",
    "print('total sum:', ts_02.sum())\n",
    "print('sum along dim=0:\\n', ts_02.sum(dim=0))\n",
    "print('sum along dim=1:\\n', ts_02.sum(dim=1))\n",
    "print('sum along dim=2:\\n', ts_02.sum(dim=2))\n",
    "print('sum along dim=-1:\\n', ts_02.sum(dim=-1))\n",
    "\n",
    "print('max overall:', ts_02.max())\n",
    "print('max along dim=0:', ts_02.max(dim=0))# max값과 max가 위치한 index값을 함께 반환. \n",
    "print('max along dim=1:', ts_02.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "sum along dim=(1, 2):\n",
      " tensor([ 66, 210])\n",
      "sum along dim=(2, 1):\n",
      " tensor([ 66, 210])\n"
     ]
    }
   ],
   "source": [
    "print(ts_02)\n",
    "print('sum along dim=(1, 2):\\n', ts_02.sum(dim=(1, 2)))\n",
    "print('sum along dim=(2, 1):\\n', ts_02.sum(dim=(2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "sum along dim=(0, 1):\n",
      " tensor([60, 66, 72, 78])\n",
      "sum along dim=(1, 0):\n",
      " tensor([60, 66, 72, 78])\n"
     ]
    }
   ],
   "source": [
    "print(ts_02)\n",
    "print('sum along dim=(0, 1):\\n', ts_02.sum(dim=(0, 1)))\n",
    "print('sum along dim=(1, 0):\\n', ts_02.sum(dim=(1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "sum along dim=(-1):\n",
      " tensor([[ 6, 22, 38],\n",
      "        [54, 70, 86]])\n",
      "sum along dim=(-2, -1):\n",
      " tensor([ 66, 210])\n"
     ]
    }
   ],
   "source": [
    "print(ts_02)\n",
    "print('sum along dim=(-1):\\n', ts_02.sum(dim=(-1)))\n",
    "print('sum along dim=(-2, -1):\\n', ts_02.sum(dim=(-2, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### argmax() 수행\n",
    "* max()는 tensor내의 가장 큰 값을 반환하지만, argmax()는 가장 큰값을 가지는 index를 반환. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6850, 0.9355, 0.2900, 0.3991, 0.7470, 0.0215, 0.0654, 0.7855, 0.3883,\n",
      "        0.6340])\n",
      "tensor(0.9355) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)  # random 수행 시 마다 동일 값 생성을 위한 seed값 할당. \n",
    "\n",
    "ts_01 = torch.rand(size=(10,))\n",
    "print(ts_01)\n",
    "print(ts_01.max(), ts_01.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6850, 0.9355, 0.2900, 0.3991, 0.7470],\n",
      "        [0.0215, 0.0654, 0.7855, 0.3883, 0.6340],\n",
      "        [0.9447, 0.4773, 0.2861, 0.3887, 0.1099],\n",
      "        [0.3606, 0.8450, 0.8059, 0.0520, 0.3438]])\n",
      "tensor([1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "ts_01 = torch.rand(size=(4, 5))\n",
    "print(ts_01)\n",
    "print(ts_01.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9355, 0.7855, 0.9447, 0.8450]),\n",
      "indices=tensor([1, 2, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "# dim값이 입력된 max()는 max값과 max위치의 index를 반환\n",
    "print(ts_01.max(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "_, val_index = ts_01.max(dim=-1)\n",
    "print( val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 3, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(ts_01.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### squeeze()와 unsqueeze()\n",
    "* squeeze()는 1로 되어 있는 차원값을 없앤 tensor반환. unsqueeze는 기존 차원을 1차원 증가시킴.\n",
    "* squeeze(dim=0)과 같이 해당 dim을 지정하면 해당 차원값만(1로 되어 있어야 함) 삭제하여 재 구성한 tensor 반환\n",
    "* squeeze(dim=None)은 1로 되어 있는 차원값을 모두 찾아서 없앤 tensor 반환.\n",
    "* unsqueeze()는 dim=0과 같이 반드시 dim인자를 입력해 줘야 함(squeeze()도 가급적이면 반드시 dim인자 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6850, 0.9355, 0.2900, 0.3991, 0.7470],\n",
      "         [0.0215, 0.0654, 0.7855, 0.3883, 0.6340],\n",
      "         [0.9447, 0.4773, 0.2861, 0.3887, 0.1099],\n",
      "         [0.3606, 0.8450, 0.8059, 0.0520, 0.3438]]])\n",
      "ts_01 shape: torch.Size([1, 4, 5]) ts_01 squeezed shape: torch.Size([4, 5])\n",
      "tensor([[0.6850, 0.9355, 0.2900, 0.3991, 0.7470],\n",
      "        [0.0215, 0.0654, 0.7855, 0.3883, 0.6340],\n",
      "        [0.9447, 0.4773, 0.2861, 0.3887, 0.1099],\n",
      "        [0.3606, 0.8450, 0.8059, 0.0520, 0.3438]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "ts_01 = torch.rand(size=(1, 4, 5))\n",
    "print(ts_01)\n",
    "\n",
    "ts_01_1 = ts_01.squeeze()\n",
    "print('ts_01 shape:', ts_01.shape, 'ts_01 squeezed shape:', ts_01_1.shape)\n",
    "print(ts_01_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1]) torch.Size([4, 1]) torch.Size([1, 4]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# squeeze(dim=0)과 같이 dim 인자 적용\n",
    "ts_01 = torch.rand(size=(1, 4, 1))\n",
    "ts_01_1 = ts_01.squeeze(dim=0)\n",
    "ts_01_2 = ts_01.squeeze(dim=-1)\n",
    "ts_01_3 = ts_01.squeeze(dim=(0, -1))\n",
    "\n",
    "print(ts_01.shape, ts_01_1.shape, ts_01_2.shape, ts_01_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01 shape: torch.Size([1, 3, 64, 64]) ts_01 squeezed shape: torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# 보통은 batch가 포함된 4차원 이미지 tensor에서 batch가 1일 경우 3차원 단일 이미지 tensor로 변환하는데 주로 사용 \n",
    "ts_01 = torch.rand(size=(1, 3, 64, 64))\n",
    "ts_01_1 = ts_01.squeeze(dim=0)\n",
    "print('ts_01 shape:', ts_01.shape, 'ts_01 squeezed shape:', ts_01_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6850, 0.9355, 0.2900, 0.3991, 0.7470],\n",
      "        [0.0215, 0.0654, 0.7855, 0.3883, 0.6340],\n",
      "        [0.9447, 0.4773, 0.2861, 0.3887, 0.1099],\n",
      "        [0.3606, 0.8450, 0.8059, 0.0520, 0.3438]])\n",
      "ts_01 shape: torch.Size([4, 5]) ts_01 unsqueezed shape: torch.Size([1, 4, 5])\n",
      "tensor([[[0.6850, 0.9355, 0.2900, 0.3991, 0.7470],\n",
      "         [0.0215, 0.0654, 0.7855, 0.3883, 0.6340],\n",
      "         [0.9447, 0.4773, 0.2861, 0.3887, 0.1099],\n",
      "         [0.3606, 0.8450, 0.8059, 0.0520, 0.3438]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "ts_01 = torch.rand(size=(4, 5))\n",
    "print(ts_01)\n",
    "\n",
    "ts_01_1 = ts_01.unsqueeze(dim=0) # dim 인자가 반드시 사용되어야 함. \n",
    "print('ts_01 shape:', ts_01.shape, 'ts_01 unsqueezed shape:', ts_01_1.shape)\n",
    "print(ts_01_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01 shape: torch.Size([3, 64, 64]) ts_01 unsqueezed shape: torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# 보통은 3차원 단일 이미지 tensor를 batch 포함 4차원 이미지 tensor로 변환 시 자주 사용\n",
    "ts_01 = torch.rand(size=(3, 64, 64))\n",
    "ts_01_1 = ts_01.unsqueeze(dim=0)\n",
    "print('ts_01 shape:', ts_01.shape, 'ts_01 unsqueezed shape:', ts_01_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item() \n",
    "* tensor 자체가 아니라 tensor값만 반환하는 데 사용. tensor가 값을 1개만 가지고 있을 경우 이 값을 python scalar 값으로 반환\n",
    "* 1차원 tensor에 값이 하나만 있거나 tensor가 scalar type일 경우만 item() 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([1]) 1\n",
      "ts_01 item(): 1\n",
      "torch.int64 torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.tensor([1])\n",
    "print(ts_01.dtype, ts_01.shape, ts_01.ndim)\n",
    "print('ts_01 item():', ts_01.item())\n",
    "\n",
    "ts_02 = torch.tensor(1)\n",
    "print(ts_02.dtype, ts_02.shape, ts_02.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([2]) 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ts_01 = torch.tensor([\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(ts_01.dtype, ts_01.shape, ts_01.ndim)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mts_01 item():\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mts_01\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# 아래는 1차원 이지만 값이 2개 이상이므로 item() 호출 시 오류 발생. \n",
    "ts_01 = torch.tensor([1, 2])\n",
    "print(ts_01.dtype, ts_01.shape, ts_01.ndim)\n",
    "print('ts_01 item():', ts_01.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### indexing\n",
    "* tensor의 indexing은 numpy array indexing과 매우 유사\n",
    "* 단일 지정(integer) indexing, 슬라이싱(:) indexing, Fancy(List) indexing, Boolean indexing 외에도 다양한 indexing을 제공\n",
    "* 단일 지정 indexing을 수행 할 경우 원본 tensor를 한 차원 줄인 tensor반환(numpy array도 마찬가지)\n",
    "* numpy와 다르게 pytorch boolean indexing을 1차원 tensor를 반환(numpy array는 원본 차원 유지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.arange(0, 10).view(2, 5)\n",
    "print(ts_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01[0, 0]: tensor(0) ts_01[0, 1]: tensor(1)\n",
      "ts_01[1, 0]: tensor(5) ts_01[1, 2]: tensor(7)\n",
      "torch.Size([]) 0 torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "# 지정 인덱싱 적용\n",
    "print('ts_01[0, 0]:', ts_01[0, 0], 'ts_01[0, 1]:', ts_01[0, 1])\n",
    "print('ts_01[1, 0]:', ts_01[1, 0], 'ts_01[1, 2]:', ts_01[1, 2])\n",
    "print(ts_01[0, 0].shape, ts_01[0, 0].ndim, ts_01[0, :].shape, ts_01[0, :].ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "ts_01[0, :]은 tensor([0, 1, 2, 3, 4]) ts_01[:, 0]은 tensor([0, 5])\n",
      "ts_01[0, 0:3]은 tensor([0, 1, 2]) ts_01[1, 1:4]은 tensor([6, 7, 8])\n",
      "ts_01[:, :]\n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(ts_01)\n",
    "print('ts_01[0, :]은', ts_01[0, :], 'ts_01[:, 0]은', ts_01[:, 0])\n",
    "print('ts_01[0, 0:3]은', ts_01[0, 0:3], 'ts_01[1, 1:4]은', ts_01[1, 1:4])\n",
    "print('ts_01[:, :]\\n', ts_01[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_indexes: tensor([1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "random_indexes = torch.randint(0, 5, size=(4,))\n",
    "print('random_indexes:', random_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_indexes: tensor([1, 4, 4, 1])\n",
      "ts_01:\n",
      " tensor([[0.7470, 0.0215, 0.0654, 0.7855, 0.3883],\n",
      "        [0.6340, 0.9447, 0.4773, 0.2861, 0.3887],\n",
      "        [0.1099, 0.3606, 0.8450, 0.8059, 0.0520],\n",
      "        [0.3438, 0.5326, 0.5318, 0.0709, 0.8716],\n",
      "        [0.6798, 0.2956, 0.9812, 0.9813, 0.8118],\n",
      "        [0.0463, 0.9592, 0.5132, 0.3941, 0.6953],\n",
      "        [0.7350, 0.0309, 0.8294, 0.3368, 0.6413],\n",
      "        [0.6471, 0.5964, 0.9792, 0.8084, 0.9328],\n",
      "        [0.8772, 0.1945, 0.5616, 0.6019, 0.5040],\n",
      "        [0.0028, 0.2127, 0.0655, 0.0905, 0.2134]])\n",
      "ts_01_1:\n",
      " tensor([[0.6340, 0.9447, 0.4773, 0.2861, 0.3887],\n",
      "        [0.6798, 0.2956, 0.9812, 0.9813, 0.8118],\n",
      "        [0.6798, 0.2956, 0.9812, 0.9813, 0.8118],\n",
      "        [0.6340, 0.9447, 0.4773, 0.2861, 0.3887]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "random_indexes = torch.randint(0, 5, size=(4,))\n",
    "print('random_indexes:', random_indexes)\n",
    "\n",
    "ts_01 = torch.rand(size=(10, 5))\n",
    "print('ts_01:\\n', ts_01)\n",
    "\n",
    "ts_01_1 = ts_01[random_indexes] # fancy indexing 적용\n",
    "print('ts_01_1:\\n', ts_01_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "tensor([[False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True]])\n",
      "tensor([5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.arange(0, 10).view(2, 5)\n",
    "print(ts_01)\n",
    "\n",
    "mask = ts_01 > 4\n",
    "print(mask)\n",
    "print(ts_01[mask]) # pytorch tensor의 boolean indexing은 1차원 tensor를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# where는 원본 배열 차원을 보존\n",
    "torch.where(ts_01 > 4, input=ts_01, other=torch.tensor(999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 내적과 행렬곱 연산 - dot()와 matmul()\n",
    "* torch의 dot() 연산은 1차원 tensor만 가능(vector dot product)\n",
    "* torch의 matmul() 연산은 1차원-2차원 tensor간, 2차원 tensor간(matrix) 행렬곱 연산 수행\n",
    "* matmul()의 경우 3차원 이상의 tensor가 입력될 경우 맨 뒤의 2개 차원을 행렬로, 앞의 차원들은 batch로 간주하고 행렬곱 연산 수행\n",
    "![행렬곱](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/matmul.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01: tensor([1, 2, 3]) ts_02: tensor([4, 5, 6])\n",
      "ts_03: tensor(32)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "ts_01 = torch.arange(1, 4)\n",
    "ts_02 = torch.arange(4, 7)\n",
    "print('ts_01:', ts_01, 'ts_02:', ts_02)\n",
    "\n",
    "ts_03 = torch.dot(ts_01, ts_02) # dot()연산은 1차원끼리만 가능. \n",
    "print('ts_03:', ts_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      " ts_02:\n",
      " tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "ts_03:\n",
      " tensor([[ 58,  64],\n",
      "        [139, 154]])\n"
     ]
    }
   ],
   "source": [
    "ts_01 = torch.arange(1, 7).view(2, 3)\n",
    "ts_02 = torch.arange(7, 13).view(3, 2)\n",
    "print('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n",
    "\n",
    "ts_03 = torch.matmul(ts_01, ts_02) # 2차원 행렬 곱 연산 수행\n",
    "print('ts_03:\\n', ts_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01:\n",
      " tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]]) \n",
      " ts_02:\n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]]])\n",
      "ts_03:\n",
      " tensor([[[  70,   76,   82,   88,   94],\n",
      "         [ 190,  212,  234,  256,  278],\n",
      "         [ 310,  348,  386,  424,  462]],\n",
      "\n",
      "        [[1510, 1564, 1618, 1672, 1726],\n",
      "         [1950, 2020, 2090, 2160, 2230],\n",
      "         [2390, 2476, 2562, 2648, 2734]]])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 이상의 행렬 곱. batch size는 서로 동일해야 함. 단 둘중 한개가 batch size 1인 경우는 상관 없음. \n",
    "ts_01 = torch.arange(0, 24).view(2, 3, 4) # batch size 2를 가지는 3x4 행렬\n",
    "ts_02 = torch.arange(0, 40).view(2, 4, 5)  # batch size 2을 가지는 4x5 행렬\n",
    "print('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n",
    "\n",
    "ts_03 = torch.matmul(ts_01, ts_02)  # 맨 앞차원은 배치로 간주하고 뒤 차원 2개를 행렬 곱 연산 수행. \n",
    "print('ts_03:\\n', ts_03)\n",
    "print(ts_03.shape) # 출력 shape는 (2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 70,  76,  82,  88,  94],\n",
       "        [190, 212, 234, 256, 278],\n",
       "        [310, 348, 386, 424, 462]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(\n",
    "torch.tensor(\n",
    "[[ 0,  1,  2,  3],\n",
    "[ 4,  5,  6,  7],\n",
    "[ 8,  9, 10, 11]]), \n",
    "torch.tensor(\n",
    "[[ 0,  1,  2,  3,  4],\n",
    "[ 5,  6,  7,  8,  9],\n",
    "[10, 11, 12, 13, 14],\n",
    "[15, 16, 17, 18, 19]]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_01:\n",
      " tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]]) \n",
      " ts_02:\n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m ts_02 = torch.arange(\u001b[32m0\u001b[39m, \u001b[32m60\u001b[39m).view(\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m)  \u001b[38;5;66;03m# batch size=3을 가지는 4x5 행렬\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mts_01:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, ts_01, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mts_02:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, ts_02)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m ts_03 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_01\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_02\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 맨 앞차원은 배치로 간주하고 뒤 차원 2개를 행렬 곱 연산 수행. \u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(ts_03)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(ts_03.shape)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# batch size는 서로 동일해야 함. 단 둘중 한개가 batch size 1인 경우는 상관 없음.\n",
    "ts_01 = torch.arange(0, 24).view(2, 3, 4) # batch size 2를 가지는 3x4 행렬\n",
    "ts_02 = torch.arange(0, 60).view(3, 4, 5)  # batch size=3을 가지는 4x5 행렬\n",
    "print('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n",
    "\n",
    "ts_03 = torch.matmul(ts_01, ts_02)  # 맨 앞차원은 배치로 간주하고 뒤 차원 2개를 행렬 곱 연산 수행. \n",
    "print(ts_03)\n",
    "print(ts_03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
