{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module을 상속받아 Custom Model 생성하기\n",
    "* 입력 Feature 갯수가 784이고 출력 feature 갯수가 100인 Linear Layer와 ReLU Activation Layer, 최종 10개의 출력 feature를 가지는 Linear Layer를 기반으로 모델 생성.\n",
    "* \\_\\_init\\_\\_(self,..)에서 해당 Layer들 선언\n",
    "* forward(self, x)에서 입력 tensor의 forward pass를 기술하면서 이들 Layer들을 연결\n",
    "* 모델 입력은 반드시 tensor가 되어야 하며, 출력도 tensor가 됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch import nn\n",
    "\n",
    "# Custom Model 생성. \n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        # 반드시 super()를 호출. \n",
    "        super().__init__()\n",
    "        #Linear Layer와 ReLU Layer 생성. \n",
    "        self.linear_01 = nn.Linear(in_features=784, out_features=100)\n",
    "        self.relu_01 = nn.ReLU()\n",
    "        self.linear_02 = nn.Linear(in_features=100, out_features=num_classes)\n",
    "        \n",
    "    # 순방향 전파(Pass Forward) 기술.\n",
    "    def forward(self, x):\n",
    "        x = self.linear_01(x)\n",
    "        x = self.relu_01(x)\n",
    "        output = self.linear_02(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#임의의 입력 tensor 생성. \n",
    "input_tensor = torch.randn(size=(64, 784))\n",
    "print(input_tensor.size())\n",
    "\n",
    "# LinearModel 객체 생성. __init__(self, num_classes)에 선언된 객체 초기화 인자 입력하여 생성. \n",
    "linear_model = LinearModel(num_classes=10)\n",
    "\n",
    "# LinearModel 객체는 Callable Object이므로 LinearModel 객체에 함수 호출과 유사한 형태로 입력 인자 전달하여 forward()메소드 호출. \n",
    "output_tensor = linear_model(input_tensor)\n",
    "print(output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer(nn.Linear, nn.Conv2d, nn.ReLU, nn.MaxPool2d등) 살펴보기\n",
    "* Pytorch의 Layer는 신경망(Neural Network)을 쉽게 생성하기 위한 직관적인 building block\n",
    "* Layer 역시 nn.Module을 상속 받아 생성되며, 자동미분(Auto differentiation)과 GPU device 지원\n",
    "* Layer들은 입력 데이터에 적용되는 구조와 변환을 기술하여 선형 변환(Liner transformation), Convolution 적용, 활성함수 적용(Activation), Pooling과 Normalization 등의 작업을 수행.\n",
    "* 내부적으로 학습 파라미터를 가지고 있는 Layer(nn.Linear, nn.Conv2d)와 주로 변환만을 수행하는 Layer(nn.ReLU, nn.MaxPool2d)등이 있음.\n",
    "* Callable Object의 생성과 입력 데이터 전달 방식과 비슷하게, 생성 인자를 입력하여 Layer객체를 생성 한 뒤 변환될 입력 tensor를 객체의 인자로 입력해 주는 방식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0056,  0.0183,  0.0219,  ..., -0.0115,  0.0077,  0.0054],\n",
      "        [ 0.0126,  0.0324, -0.0273,  ...,  0.0109,  0.0268,  0.0040],\n",
      "        [-0.0054, -0.0152, -0.0300,  ...,  0.0326, -0.0179, -0.0236],\n",
      "        ...,\n",
      "        [-0.0273, -0.0251, -0.0287,  ...,  0.0023, -0.0080,  0.0236],\n",
      "        [-0.0081,  0.0039,  0.0295,  ..., -0.0174, -0.0330,  0.0265],\n",
      "        [ 0.0168, -0.0001, -0.0025,  ..., -0.0008, -0.0114,  0.0149]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 9.8777e-03, -1.8693e-02,  3.1205e-02,  1.6275e-02, -2.7545e-03,\n",
      "        -2.2487e-02, -1.6596e-02, -2.0752e-02, -1.7975e-02, -2.9267e-02,\n",
      "         6.8150e-03,  2.1224e-02, -2.3022e-02, -1.1930e-02, -3.2589e-02,\n",
      "         1.3139e-02,  7.4696e-03,  1.6216e-02, -2.1187e-02, -8.4596e-03,\n",
      "        -1.2772e-02,  5.5135e-04, -2.5150e-02,  2.7795e-02, -1.6036e-02,\n",
      "         1.3935e-02, -1.8359e-02,  3.1903e-02, -1.2559e-02,  3.9326e-05,\n",
      "         2.1647e-03,  3.2502e-02, -1.7871e-02,  9.5639e-03, -1.8214e-02,\n",
      "         1.3821e-03, -2.7469e-02,  1.0577e-02, -2.5148e-04, -3.2524e-02,\n",
      "         1.1601e-02, -3.0008e-02,  3.4096e-02, -1.4461e-02,  1.5723e-02,\n",
      "         2.4123e-02,  1.4174e-03,  1.8917e-02, -6.0837e-03,  3.4773e-02,\n",
      "         2.0573e-02,  6.9766e-03,  3.3137e-03, -9.0009e-03, -3.1549e-02,\n",
      "        -7.1538e-03,  2.9686e-03,  2.5175e-02, -7.5360e-03, -2.0904e-02,\n",
      "        -3.5462e-02,  3.1666e-02,  8.3024e-04, -1.1252e-02,  1.4110e-02,\n",
      "        -1.7545e-02, -2.1066e-02,  3.0858e-02, -8.1049e-03, -1.6429e-02,\n",
      "         7.8364e-04,  1.5427e-02, -2.0988e-02,  2.3959e-02,  3.1552e-02,\n",
      "        -5.6519e-03, -1.7343e-02, -2.5119e-03, -1.2076e-02, -2.9284e-03,\n",
      "        -4.7702e-03,  6.6002e-03, -4.2272e-03,  7.4146e-03,  2.3811e-02,\n",
      "        -3.3871e-02,  3.3739e-02,  5.5616e-03,  1.3914e-02, -2.2549e-02,\n",
      "        -2.0205e-02,  1.2823e-02, -3.5696e-02, -3.1639e-02,  2.1565e-03,\n",
      "        -8.4649e-03,  2.0030e-02, -4.7003e-03, -3.0538e-02,  1.8845e-02],\n",
      "       requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "linear_01= nn.Linear(in_features=784, out_features=100)\n",
    "# 학습 파라미터를 가지고 있음.\n",
    "print(linear_01.weight)\n",
    "print(linear_01.bias)\n",
    "\n",
    "# 학습 파라미터는 nn.parameter.Parameter 타입이며, nn.parameter.Parameter는 학습이 가능한(자동 미분) 특별한 타입의 Tensor임. \n",
    "print(type(linear_01.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# linear_01= nn.Linear(in_features=784, out_features=100)\n",
    "# weight의 shape는 matmul()을 위해서 (in_features, out_features)의 행렬 위치가 바뀌는 Transpose 적용되어야 함. \n",
    "print(linear_01.weight.shape, linear_01.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Parameter 는 학습이 가능한(자동 미분) 특별한 타입의 Tensor임. \n",
    "* nn.Module을 상속받은 모든 객체는 자신이 가지는 Parameter Tensor를 Optimizer에 등록할 수 있음.\n",
    "* 일반 Tensor역시 requires_grad를 수행하면 자동 미분은 가능하지만 Optimizer에 등록 할 수는 없으므로 optimizer에서 grad upgrade를 수행할 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0056,  0.0183,  0.0219,  ..., -0.0115,  0.0077,  0.0054],\n",
      "        [ 0.0126,  0.0324, -0.0273,  ...,  0.0109,  0.0268,  0.0040],\n",
      "        [-0.0054, -0.0152, -0.0300,  ...,  0.0326, -0.0179, -0.0236],\n",
      "        ...,\n",
      "        [-0.0273, -0.0251, -0.0287,  ...,  0.0023, -0.0080,  0.0236],\n",
      "        [-0.0081,  0.0039,  0.0295,  ..., -0.0174, -0.0330,  0.0265],\n",
      "        [ 0.0168, -0.0001, -0.0025,  ..., -0.0008, -0.0114,  0.0149]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 9.8777e-03, -1.8693e-02,  3.1205e-02,  1.6275e-02, -2.7545e-03,\n",
      "        -2.2487e-02, -1.6596e-02, -2.0752e-02, -1.7975e-02, -2.9267e-02,\n",
      "         6.8150e-03,  2.1224e-02, -2.3022e-02, -1.1930e-02, -3.2589e-02,\n",
      "         1.3139e-02,  7.4696e-03,  1.6216e-02, -2.1187e-02, -8.4596e-03,\n",
      "        -1.2772e-02,  5.5135e-04, -2.5150e-02,  2.7795e-02, -1.6036e-02,\n",
      "         1.3935e-02, -1.8359e-02,  3.1903e-02, -1.2559e-02,  3.9326e-05,\n",
      "         2.1647e-03,  3.2502e-02, -1.7871e-02,  9.5639e-03, -1.8214e-02,\n",
      "         1.3821e-03, -2.7469e-02,  1.0577e-02, -2.5148e-04, -3.2524e-02,\n",
      "         1.1601e-02, -3.0008e-02,  3.4096e-02, -1.4461e-02,  1.5723e-02,\n",
      "         2.4123e-02,  1.4174e-03,  1.8917e-02, -6.0837e-03,  3.4773e-02,\n",
      "         2.0573e-02,  6.9766e-03,  3.3137e-03, -9.0009e-03, -3.1549e-02,\n",
      "        -7.1538e-03,  2.9686e-03,  2.5175e-02, -7.5360e-03, -2.0904e-02,\n",
      "        -3.5462e-02,  3.1666e-02,  8.3024e-04, -1.1252e-02,  1.4110e-02,\n",
      "        -1.7545e-02, -2.1066e-02,  3.0858e-02, -8.1049e-03, -1.6429e-02,\n",
      "         7.8364e-04,  1.5427e-02, -2.0988e-02,  2.3959e-02,  3.1552e-02,\n",
      "        -5.6519e-03, -1.7343e-02, -2.5119e-03, -1.2076e-02, -2.9284e-03,\n",
      "        -4.7702e-03,  6.6002e-03, -4.2272e-03,  7.4146e-03,  2.3811e-02,\n",
      "        -3.3871e-02,  3.3739e-02,  5.5616e-03,  1.3914e-02, -2.2549e-02,\n",
      "        -2.0205e-02,  1.2823e-02, -3.5696e-02, -3.1639e-02,  2.1565e-03,\n",
      "        -8.4649e-03,  2.0030e-02, -4.7003e-03, -3.0538e-02,  1.8845e-02],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Layer의 parameters() 메소드는 Layer가 가지는 모든 parameter들을 iteration으로 반환함. \n",
    "for parameter in linear_01.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "torch.Size([100, 784]) True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_01 = torch.rand(size=(100, 784))\n",
    "print(tensor_01.requires_grad)\n",
    "\n",
    "param_01 = nn.Parameter(data=tensor_01)\n",
    "print(param_01.shape, param_01.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성 모듈(Layer 및 서브모듈) 살펴보기\n",
    "* 서브모듈(submodule)은 nn.Module을 상속 받아 생성된 컴포넌트(Layer도 서브모듈). 보통은 여러개의 Layer등을 엮어서 만들어지는 또 다른 클래스(블록)라는 의미로 통용되며, 모델이 복잡한 구조로 되어 있을 경우 특정 구조를 작게 블록화 시키는데 적용됨. \n",
    "* 서브모듈 또한 nn.Module에서 제공하는 여러기능을 가지게 됨(자식 모듈 등록, 파라미터 자동 등록 및 자동 미분 수행등)\n",
    "* 서브모듈 생성 시 반드시 생성자 메소드와  forward() 메소드를 구현해야 함.\n",
    "* 강의 진행 시 용어 정리는 아래와 같이 하겠음.\n",
    "    * 모델: 최종으로 만들어지는 네트웍 모델\n",
    "    * 서브모듈(또는 Block): 여러개의 Layer로 연결되어 만들어 지는 블록형 모듈.\n",
    "    * 서브모듈(모듈): Layer와 서브모듈등 nn.Module을 상속받은 모든 객체\n",
    "    * Layer: nn.Linear와 같은 Layer\n",
    "    * nn.Module: nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T08:19:31.339863Z",
     "iopub.status.busy": "2025-02-17T08:19:31.339569Z",
     "iopub.status.idle": "2025-02-17T08:19:34.327504Z",
     "shell.execute_reply": "2025-02-17T08:19:34.326652Z",
     "shell.execute_reply.started": "2025-02-17T08:19:31.339834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 서브 모듈 생성.\n",
    "class SimpleBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear_01 = nn.Linear(in_features=in_features,\n",
    "                                   out_features=out_features)\n",
    "        self.relu_01 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_01(x)\n",
    "        x = self.relu_01(x)\n",
    "        return x\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        # 반드시 super()를 호출. \n",
    "        super().__init__()\n",
    "        # 서브 모듈인 SimpleBlock 생성\n",
    "        self.simple_01 = SimpleBlock(in_features=784,\n",
    "                                     out_features=100)\n",
    "        self.linear_02 = nn.Linear(in_features=100, out_features=num_classes)\n",
    "        \n",
    "    # 순방향 전파(Pass Forward) 기술.\n",
    "    def forward(self, x):\n",
    "        x = self.simple_01(x)\n",
    "        output = self.linear_02(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T08:19:34.331288Z",
     "iopub.status.busy": "2025-02-17T08:19:34.331063Z",
     "iopub.status.idle": "2025-02-17T08:19:34.412748Z",
     "shell.execute_reply": "2025-02-17T08:19:34.411741Z",
     "shell.execute_reply.started": "2025-02-17T08:19:34.331267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(size=(64, 784))\n",
    "print(input_tensor.size())\n",
    "\n",
    "# LinearModel 객체 생성. __init__(self, num_classes)에 선언된 객체 초기화 인자 입력하여 생성. \n",
    "linear_model = LinearModel(num_classes=10)\n",
    "\n",
    "# LinearModel 객체는 Callable Object이므로 LinearModel 객체에 함수 호출과 유사한 형태로 입력 인자 전달하여 forward()메소드 호출. \n",
    "output_tensor = linear_model(input_tensor)\n",
    "print(output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델이 가지는 모든 모듈(Layer, 서브모듈) 확인하기\n",
    "* modules() 메소드는 자신의 모듈을 포함하여 Nesting된 서브 모듈(Layer포함하여 nn.Module을 상속받은 모든 클래스)를 출력\n",
    "* named_modules() 메소드는 자신의 모듈을 포함하여 Nesting된 서브 모듈까지 모듈명과 모듈 클래스를 출력\n",
    "* 모델이 가지는 내부 멤버변수(self로 지정된 변수)는 객체명.변수명으로 바로 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (simple_01): SimpleBlock(\n",
      "    (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "  )\n",
      "  (linear_02): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 출력\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (simple_01): SimpleBlock(\n",
      "    (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "  )\n",
      "  (linear_02): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "SimpleBlock(\n",
      "  (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu_01): ReLU()\n",
      ")\n",
      "Linear(in_features=784, out_features=100, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=100, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 자신의 모듈을 포함하여 Nesting된 서브 모듈까지 모두 출력\n",
    "for module in linear_model.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Name: , Module: LinearModel(\n",
      "  (simple_01): SimpleBlock(\n",
      "    (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "  )\n",
      "  (linear_02): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "Module Name: simple_01, Module: SimpleBlock(\n",
      "  (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu_01): ReLU()\n",
      ")\n",
      "Module Name: simple_01.linear_01, Module: Linear(in_features=784, out_features=100, bias=True)\n",
      "Module Name: simple_01.relu_01, Module: ReLU()\n",
      "Module Name: linear_02, Module: Linear(in_features=100, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# named_modules() 메소드는 자신의 모듈을 포함하여 Nesting된 서브 모듈까지 모듈명과 모듈 클래스를 출력\n",
    "for name, module in linear_model.named_modules():\n",
    "    print(f\"Module Name: {name}, Module: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule Name: simple_01, Submodule: SimpleBlock(\n",
      "  (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu_01): ReLU()\n",
      ")\n",
      "Submodule Name: linear_02, Submodule: Linear(in_features=100, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# named_children() 메소드는 자기 직계 서브 모듈만 모듈명과 모듈 클래스 출력\n",
    "for name, module in linear_model.named_children():\n",
    "    print(f\"Submodule Name: {name}, Submodule: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_01: SimpleBlock(\n",
      "  (linear_01): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu_01): ReLU()\n",
      ")\n",
      "linear_02: Linear(in_features=100, out_features=10, bias=True)\n",
      "linear_01 in simple_01: Linear(in_features=784, out_features=100, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#모델이 가지는 내부 멤버변수(self로 지정된 변수)는 객체명.변수명으로 바로 접근 가능\n",
    "print('simple_01:', linear_model.simple_01)\n",
    "print('linear_02:', linear_model.linear_02)\n",
    "print('linear_01 in simple_01:', linear_model.simple_01.linear_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델의 모든 Parameter 가져오기\n",
    "* nn.Module을 상속 받은 모든 클래스는 등록된 Parameter Tensor를 parameters()로 가져 올 수 있음.\n",
    "* 모델이 가지는 서브모듈들의 모든 parameter들을 parameters()로 가져 올 수 있음.\n",
    "* named_parameter()는 parameter를 가지는 서브모듈/Layer의 weight/bias와 parameter tensor를 모두 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0048,  0.0105,  0.0313,  ..., -0.0306, -0.0232, -0.0229],\n",
      "        [ 0.0094,  0.0275,  0.0215,  ..., -0.0352,  0.0215, -0.0234],\n",
      "        [-0.0076,  0.0288, -0.0229,  ..., -0.0080,  0.0225, -0.0232],\n",
      "        ...,\n",
      "        [ 0.0232,  0.0188, -0.0173,  ..., -0.0006,  0.0336, -0.0308],\n",
      "        [-0.0108, -0.0002,  0.0268,  ..., -0.0135,  0.0225,  0.0349],\n",
      "        [ 0.0219,  0.0156, -0.0337,  ..., -0.0017,  0.0205, -0.0292]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.3991e-02,  5.2879e-03,  3.7704e-04, -3.2616e-02, -3.6454e-03,\n",
      "         1.0816e-02,  5.7917e-03, -1.1305e-03, -2.3250e-02,  3.9217e-03,\n",
      "         1.9031e-02,  8.8242e-03, -3.2714e-02, -2.0103e-02,  3.2724e-02,\n",
      "        -3.3922e-02, -2.5260e-02,  2.6187e-02, -1.7119e-03,  1.1702e-02,\n",
      "         2.3196e-02, -3.2545e-02,  7.6600e-03,  9.0178e-04,  2.4319e-02,\n",
      "         3.1890e-02, -3.4113e-03,  2.1267e-02, -4.4083e-03,  3.0923e-02,\n",
      "         1.2813e-03,  2.8033e-02,  3.0571e-02, -2.9288e-02,  1.4436e-02,\n",
      "        -3.2084e-02,  5.0021e-03, -3.4131e-02, -1.8752e-03,  5.1321e-03,\n",
      "        -1.8585e-02, -1.9904e-03,  2.7740e-02, -8.4171e-03, -3.2416e-05,\n",
      "         4.4462e-03,  3.5500e-02, -6.3054e-03, -2.4877e-02, -3.4635e-02,\n",
      "        -2.7977e-02, -1.4883e-02, -6.7155e-04, -3.2891e-02, -3.5715e-04,\n",
      "        -1.9070e-02, -3.1718e-02,  2.5436e-02, -4.9667e-03,  2.7227e-02,\n",
      "         2.0300e-02,  3.0113e-02,  3.1666e-03, -3.4231e-02,  2.9263e-02,\n",
      "         3.8274e-03,  2.1902e-02,  1.1978e-02,  1.4659e-02, -3.1171e-02,\n",
      "        -3.5712e-02, -2.3608e-02,  2.5713e-02,  2.3413e-02, -1.4694e-02,\n",
      "        -2.4033e-03, -1.6665e-02,  2.6455e-03, -3.8625e-03,  1.1416e-02,\n",
      "        -2.7844e-03,  1.3207e-02,  1.7864e-02, -2.9576e-03,  1.2560e-02,\n",
      "        -1.4037e-02, -2.6484e-02, -2.4104e-02, -5.4144e-03, -1.7473e-02,\n",
      "         3.5325e-02,  4.0050e-03, -1.7891e-02, -1.8134e-02,  2.1646e-02,\n",
      "         3.2086e-02,  2.0971e-02,  2.9084e-02,  2.1637e-02,  1.6983e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-8.4089e-02,  9.8894e-02,  3.8790e-03,  4.1091e-02, -2.5528e-02,\n",
      "          7.9240e-02,  9.9972e-02, -8.5350e-02,  5.2064e-02, -4.5945e-02,\n",
      "          4.0682e-02,  6.6800e-02, -3.4495e-02, -2.0068e-02, -9.5570e-02,\n",
      "         -2.9888e-02, -1.5193e-02,  3.2018e-02,  8.0167e-02, -4.3620e-02,\n",
      "         -5.4560e-02, -5.4458e-02,  9.1173e-02, -5.4510e-02, -2.0059e-02,\n",
      "          1.3885e-02, -8.1386e-02, -9.3610e-02,  3.1492e-03,  6.6817e-02,\n",
      "          7.2983e-02,  7.5640e-02, -5.6154e-02, -4.1341e-02,  7.6096e-03,\n",
      "         -6.9161e-03, -4.0029e-02, -9.9330e-02, -1.9876e-02,  6.1988e-02,\n",
      "          5.8773e-02, -1.2870e-03,  9.0594e-03,  7.4365e-02, -1.2406e-02,\n",
      "         -1.3281e-02,  8.5218e-02,  1.1999e-02, -8.3439e-02,  6.7605e-02,\n",
      "         -1.1155e-02,  6.2949e-02, -1.1333e-02, -7.9139e-02,  4.9586e-02,\n",
      "          5.1632e-04, -4.5815e-02,  6.5157e-02,  6.0166e-02, -6.3098e-02,\n",
      "         -4.4558e-02,  1.9678e-02, -9.4456e-02, -6.8787e-02, -7.4374e-02,\n",
      "          8.1313e-02, -6.3390e-02, -8.0490e-02,  4.4488e-02, -1.0319e-02,\n",
      "          1.8184e-02,  9.6212e-02, -4.1965e-02,  8.1063e-02,  7.2094e-02,\n",
      "          1.0694e-02,  7.6802e-02,  2.5499e-04,  8.8484e-02,  9.7090e-02,\n",
      "         -9.4642e-02,  5.7744e-02, -1.6528e-02,  9.1017e-02,  7.2367e-02,\n",
      "         -1.0722e-02, -5.2405e-02,  3.6794e-02, -4.7335e-02, -8.9663e-02,\n",
      "         -8.6272e-03,  6.6718e-02, -3.7874e-04,  1.7937e-04,  7.2060e-02,\n",
      "         -5.8798e-03, -6.6177e-02,  7.1439e-02, -3.5010e-02,  7.3149e-02],\n",
      "        [-9.1098e-02, -3.3008e-02, -8.2609e-02,  2.8549e-02,  6.4152e-03,\n",
      "          3.2343e-02,  8.7183e-02, -9.4680e-02,  8.6120e-02,  4.5052e-02,\n",
      "          4.3212e-02,  6.8714e-02, -2.4577e-02,  7.7851e-02,  8.8904e-02,\n",
      "         -7.5656e-02, -2.7899e-02, -9.4745e-02, -2.0468e-02,  8.1806e-02,\n",
      "         -6.3046e-02, -7.4120e-02,  6.1969e-02, -4.0119e-02, -3.0918e-02,\n",
      "          6.8554e-03,  1.4647e-02,  8.0086e-02,  1.2840e-02, -5.4499e-02,\n",
      "         -1.4597e-02,  8.4054e-03, -2.7805e-02, -4.3926e-02,  5.0738e-02,\n",
      "         -4.3475e-02, -8.0831e-02, -8.0216e-02, -6.4130e-02,  8.6296e-02,\n",
      "         -6.8732e-02, -5.4230e-02, -4.1994e-02, -6.2703e-02,  1.5833e-02,\n",
      "          5.6125e-02,  5.0752e-02, -8.5107e-02, -5.1327e-03, -4.7147e-02,\n",
      "          1.4067e-02, -7.2259e-02, -6.9090e-02,  4.6787e-02, -8.3706e-02,\n",
      "          5.9854e-02,  1.9506e-02, -9.4010e-02,  3.4364e-02, -7.7359e-02,\n",
      "          9.9545e-02,  2.5043e-02, -7.5228e-02, -5.5480e-02,  8.4732e-02,\n",
      "          1.2539e-02, -1.3046e-02, -9.3770e-03,  2.5826e-03,  4.8480e-02,\n",
      "          7.8042e-02, -3.7987e-03, -9.3155e-02, -6.2031e-02,  7.0224e-03,\n",
      "         -8.2413e-02,  6.7558e-02, -5.5825e-03, -4.8831e-02,  1.7264e-02,\n",
      "         -6.0047e-02, -4.9639e-02,  8.8403e-02,  5.5319e-02, -4.7917e-02,\n",
      "          8.7918e-02, -8.5386e-02, -8.5437e-02, -4.4091e-02,  5.6535e-02,\n",
      "          5.3801e-03, -8.4948e-02,  2.0011e-02,  5.8222e-02, -9.7176e-02,\n",
      "          5.0801e-02, -6.5009e-02, -3.6566e-02,  2.8287e-02, -6.5343e-02],\n",
      "        [ 6.4240e-02,  8.8592e-02,  9.1929e-02,  6.1236e-02, -2.2141e-02,\n",
      "          8.3673e-02,  4.2454e-03,  3.3722e-02,  9.3616e-02,  8.9859e-02,\n",
      "          4.2259e-02,  3.0345e-02,  2.7000e-02, -5.4107e-02,  5.5343e-02,\n",
      "         -5.7645e-02, -4.2555e-02,  1.0622e-02, -3.5686e-02, -2.0461e-02,\n",
      "          8.2631e-02,  5.0873e-02, -5.3732e-02, -7.8721e-02,  2.6778e-02,\n",
      "         -5.2800e-03, -7.4056e-02,  4.6689e-02,  4.0859e-02,  3.4104e-02,\n",
      "          8.6237e-02, -4.7536e-02, -8.8256e-02,  3.9319e-03, -2.3805e-02,\n",
      "          4.0300e-02, -1.4995e-02, -8.4793e-03,  7.0485e-02, -6.5626e-02,\n",
      "          9.7523e-02,  8.0969e-02,  3.7006e-02, -9.2870e-02,  1.6789e-02,\n",
      "          4.7594e-02,  3.9779e-02, -5.5792e-02, -7.9265e-02, -5.9256e-02,\n",
      "          8.1188e-02,  4.3483e-02,  3.6409e-02,  7.5955e-02, -3.7363e-02,\n",
      "          5.7848e-02, -9.4225e-03,  5.6790e-02,  9.4043e-02,  6.9430e-02,\n",
      "         -1.9092e-02,  4.7550e-02, -2.3580e-02,  7.5143e-02,  3.8035e-02,\n",
      "         -1.7180e-02,  6.9311e-02, -5.2810e-02,  1.7004e-02, -3.0374e-02,\n",
      "          5.1982e-02, -6.1490e-02, -3.6120e-02, -9.7650e-02, -5.2843e-02,\n",
      "         -8.3683e-02, -5.2226e-02, -7.5376e-02,  3.4173e-02, -8.1729e-02,\n",
      "          8.3181e-02,  4.6334e-02, -7.4479e-02,  6.2361e-02, -2.2251e-03,\n",
      "          9.0409e-02, -8.4045e-02, -1.5911e-02,  5.2290e-02,  4.7215e-02,\n",
      "          8.8236e-02,  8.5656e-02,  8.0337e-02,  1.8265e-02, -2.1032e-02,\n",
      "          3.6276e-02,  3.0097e-02, -6.0101e-02, -2.1759e-03,  2.1377e-02],\n",
      "        [-2.6455e-02, -8.0417e-02,  1.8065e-02,  6.0271e-02,  3.7619e-02,\n",
      "          4.7762e-02,  9.4987e-02,  7.3176e-02, -4.9427e-02,  4.5525e-02,\n",
      "         -3.9447e-02,  4.6499e-02, -6.0014e-03, -6.5158e-02,  4.4360e-02,\n",
      "          3.1278e-02, -8.6498e-02,  1.1268e-03,  5.0896e-02,  9.6402e-02,\n",
      "          3.9910e-02, -8.5329e-02,  1.0725e-04,  2.3296e-02, -5.5842e-02,\n",
      "          9.3397e-02, -5.8063e-02,  2.3540e-02, -8.0344e-02,  5.1272e-02,\n",
      "          3.0768e-02,  7.2540e-04, -8.2825e-02,  7.4165e-02,  1.0231e-02,\n",
      "         -3.4046e-05, -9.8679e-02,  9.4494e-02, -4.1459e-02, -4.5076e-02,\n",
      "          3.6302e-02, -8.7300e-02,  5.1428e-02,  7.1677e-02, -2.9301e-02,\n",
      "         -2.3293e-02, -8.3245e-02,  3.6165e-02, -7.8038e-02, -1.3307e-02,\n",
      "         -1.7756e-02, -8.3321e-02,  3.3520e-02, -9.3109e-02,  2.0267e-03,\n",
      "         -9.9831e-03,  2.2653e-02, -3.3928e-02, -6.9083e-02,  2.2328e-02,\n",
      "         -2.5074e-02, -5.1219e-02, -3.5435e-04,  1.5677e-02,  5.3129e-03,\n",
      "         -5.1463e-02, -2.8089e-02,  9.9366e-02, -1.3738e-02, -6.2086e-02,\n",
      "         -5.5667e-02,  4.5139e-02, -7.3475e-02, -5.0083e-02,  6.1537e-02,\n",
      "         -1.1344e-02, -4.9049e-02, -2.1755e-02,  1.3343e-02, -7.2287e-02,\n",
      "          1.1206e-02,  8.0406e-02, -7.7753e-02,  7.8328e-02, -1.4773e-02,\n",
      "         -8.0005e-02,  1.0126e-02, -6.3924e-02, -1.6447e-02,  8.1308e-02,\n",
      "         -7.5674e-02,  4.9669e-02, -7.5616e-02, -2.5186e-02,  2.0938e-02,\n",
      "          7.2069e-02, -1.6965e-02, -3.2991e-02,  4.1630e-02,  3.9140e-02],\n",
      "        [-8.7072e-03,  7.6458e-02, -5.9003e-02, -3.4276e-02,  5.4768e-03,\n",
      "          2.8234e-02,  7.9328e-02,  4.9403e-02,  6.1187e-02,  2.8035e-02,\n",
      "          7.9981e-02,  3.4628e-02, -5.1811e-02, -4.0946e-03,  2.6555e-02,\n",
      "          2.8858e-02,  9.1241e-02,  3.9381e-02, -4.5353e-02,  3.8718e-02,\n",
      "          5.8365e-02, -4.8622e-02, -1.7183e-02,  5.2386e-03,  7.0687e-02,\n",
      "         -3.9993e-02,  4.1877e-02, -3.1902e-03, -3.4110e-02, -1.5198e-02,\n",
      "          4.0852e-02,  9.2827e-02, -8.8733e-02,  5.6097e-02, -2.4990e-02,\n",
      "         -8.1006e-02,  6.7861e-03, -4.6999e-02, -8.5082e-02,  6.4055e-02,\n",
      "         -4.5101e-02,  1.1239e-02,  3.3076e-02,  7.1564e-02,  3.5324e-02,\n",
      "          3.7081e-02,  1.7464e-02, -1.4520e-02,  9.2410e-02, -8.0948e-02,\n",
      "          3.7045e-02,  6.0784e-02, -4.0479e-02, -8.2928e-03,  8.1574e-02,\n",
      "         -1.8967e-02,  2.3525e-02,  5.5888e-02,  2.4697e-02,  9.5413e-03,\n",
      "          6.3926e-02,  2.8084e-02,  6.2693e-02, -8.4286e-03,  6.9108e-02,\n",
      "         -5.0654e-02,  7.7280e-02, -3.0391e-02, -9.8047e-02,  8.9797e-02,\n",
      "         -2.7083e-02,  6.7959e-02, -6.3364e-02, -1.6546e-03, -1.2439e-02,\n",
      "         -9.6006e-02, -6.1209e-03,  4.6219e-02, -3.7475e-02, -2.3409e-02,\n",
      "         -5.4305e-02,  9.2378e-03,  7.2941e-02,  8.7828e-02, -6.7204e-02,\n",
      "         -4.1352e-02,  8.0692e-02,  3.5817e-02, -4.1805e-02, -5.9268e-02,\n",
      "          6.7639e-02, -1.2127e-02,  6.4041e-02,  5.5587e-02, -6.1165e-04,\n",
      "         -9.4338e-02,  3.0277e-02, -3.9957e-02,  5.4321e-02,  5.9564e-02],\n",
      "        [-8.5245e-03,  8.6073e-02,  5.7099e-02, -5.7256e-02,  5.1295e-02,\n",
      "          6.5375e-02, -8.3731e-02,  4.3182e-02, -6.0930e-02, -8.1926e-02,\n",
      "          2.6880e-02,  2.2269e-02, -3.5400e-02,  4.3400e-02, -7.1868e-02,\n",
      "          7.9426e-02, -1.8078e-02,  5.5977e-02, -4.1838e-02,  2.4303e-02,\n",
      "          4.1525e-02,  3.2897e-02, -8.4635e-04,  3.6610e-02, -3.1397e-02,\n",
      "         -5.2945e-02,  4.7980e-02,  8.6776e-03, -3.6958e-03, -5.7484e-02,\n",
      "          8.6444e-02, -2.2655e-02, -6.2651e-02,  3.3293e-02,  7.3261e-02,\n",
      "         -4.4760e-03, -4.4733e-02, -1.6497e-03,  2.9776e-02, -9.2315e-02,\n",
      "         -9.0056e-02, -5.7479e-02, -9.6696e-03,  5.0612e-03, -5.4400e-02,\n",
      "          7.5381e-02, -2.7223e-02, -1.4679e-04, -5.9846e-02,  8.4298e-02,\n",
      "         -1.5598e-02, -9.3754e-02,  8.0629e-02,  1.9772e-02, -5.6505e-03,\n",
      "         -4.1049e-02, -1.3212e-02, -8.5221e-02, -9.8378e-02,  9.1199e-02,\n",
      "          7.7556e-02, -8.7709e-02, -3.7647e-02,  6.5502e-02, -3.4157e-02,\n",
      "          3.0448e-02, -2.7114e-02, -9.4635e-02,  1.6085e-02, -4.0508e-03,\n",
      "          7.9378e-02,  5.1683e-02, -7.7940e-02,  7.3280e-02,  2.5328e-02,\n",
      "          4.0813e-02,  1.7044e-02,  2.2787e-02, -6.0243e-02, -4.6532e-02,\n",
      "          4.4268e-03,  2.5542e-02,  7.6188e-02, -1.8463e-02, -7.9624e-02,\n",
      "          7.6130e-02, -8.8981e-02,  2.9920e-03,  1.1371e-02, -5.8963e-02,\n",
      "          5.7457e-02, -5.3583e-02, -2.0303e-02,  4.1009e-02,  8.8510e-02,\n",
      "          8.0707e-02, -1.0214e-02, -3.4746e-02, -6.2446e-02, -5.5820e-02],\n",
      "        [-6.1355e-02,  5.0177e-02, -7.4567e-02,  8.8660e-02, -8.0141e-03,\n",
      "          6.3708e-02, -6.4510e-02,  8.4399e-02, -8.0977e-02,  8.2577e-02,\n",
      "         -2.7584e-02,  4.4701e-03,  3.2005e-02, -8.3686e-02,  5.6683e-02,\n",
      "         -1.2631e-02, -8.3437e-02, -6.9993e-02,  4.2461e-02, -5.8861e-02,\n",
      "          3.5683e-02, -3.1891e-02, -5.5872e-03,  9.1623e-02,  5.3730e-02,\n",
      "          4.0536e-02,  5.1962e-02,  4.4928e-02, -7.6774e-02,  6.4054e-02,\n",
      "         -5.4319e-02,  2.2615e-02, -9.5394e-02, -6.7054e-02, -8.4663e-02,\n",
      "          7.0172e-02,  4.2289e-02, -4.7497e-02, -7.6324e-02,  8.7699e-02,\n",
      "          2.4932e-02,  4.3258e-02, -6.9650e-02, -5.3030e-02,  2.9161e-02,\n",
      "         -1.4654e-02, -3.0937e-02, -4.5945e-02, -5.3288e-02, -9.0442e-02,\n",
      "          6.6028e-02,  7.9630e-02, -6.7893e-02,  6.3260e-02, -5.9775e-02,\n",
      "          6.7477e-02, -4.1828e-02, -2.1527e-02,  7.6172e-02, -4.3950e-02,\n",
      "          2.2186e-02,  4.7094e-02,  9.1542e-02,  8.7705e-02,  2.7068e-02,\n",
      "         -6.3057e-02,  3.6073e-02,  4.0566e-02, -9.4384e-02, -6.6069e-02,\n",
      "         -8.7624e-02, -1.7786e-02, -5.2745e-02,  5.3812e-02, -7.4586e-02,\n",
      "         -7.1910e-02,  9.0805e-02,  7.8557e-02, -9.5231e-02, -6.8449e-02,\n",
      "          4.9538e-02, -2.3520e-02, -3.2910e-03,  4.9158e-02,  7.9774e-02,\n",
      "         -1.1539e-02,  9.7591e-02, -1.1153e-02, -6.7878e-03,  4.6217e-02,\n",
      "         -8.4947e-02, -1.9682e-03,  4.2853e-02, -2.4451e-02, -8.3959e-02,\n",
      "         -2.1965e-02, -8.1972e-02,  6.1601e-02, -6.4294e-02,  7.5423e-03],\n",
      "        [-3.2295e-02,  5.4437e-02, -5.7961e-02,  8.1417e-03,  6.6478e-02,\n",
      "          8.8771e-02, -2.8873e-02, -1.8590e-02,  5.8871e-02, -5.3796e-02,\n",
      "         -5.5774e-02, -8.5922e-02,  5.2536e-02, -8.6441e-02, -9.5542e-02,\n",
      "          4.7100e-02, -7.7339e-02, -9.2157e-02,  6.2407e-02,  1.1779e-02,\n",
      "          9.2024e-02, -4.6958e-02,  6.0360e-02,  7.1370e-02, -4.6898e-02,\n",
      "         -2.0003e-04, -9.6513e-02, -5.9708e-02, -6.5359e-04,  4.9460e-02,\n",
      "          7.9351e-02,  1.9638e-03,  9.0674e-02, -4.3511e-02, -4.7738e-02,\n",
      "         -1.0008e-02,  9.7743e-02,  3.3678e-02, -6.9547e-02,  1.9351e-02,\n",
      "          7.9207e-02, -7.0163e-02, -1.7436e-02, -9.5109e-02,  7.9005e-02,\n",
      "          3.5578e-02, -3.1933e-02, -9.6918e-03, -6.5298e-02,  5.4843e-02,\n",
      "         -7.4278e-02,  5.8527e-02, -4.9071e-02,  2.3811e-02, -8.0556e-02,\n",
      "         -8.4740e-02, -7.6407e-04,  7.8981e-02, -1.9961e-02,  2.3511e-02,\n",
      "          9.2492e-02, -3.0594e-02, -7.8846e-02,  6.2555e-02, -6.3848e-02,\n",
      "         -9.6088e-02, -9.5906e-02,  3.5628e-02, -8.2881e-02, -7.0706e-03,\n",
      "          8.8717e-02, -4.6564e-02, -4.0287e-02,  4.0287e-02, -7.2418e-02,\n",
      "         -8.4595e-02,  1.2664e-02,  4.7587e-02,  6.6266e-02,  6.7988e-02,\n",
      "         -9.1039e-03,  9.9915e-02, -6.4913e-02,  3.1849e-03,  4.3146e-02,\n",
      "         -1.6839e-02,  1.7003e-02,  7.3962e-02, -6.0852e-02,  6.8909e-03,\n",
      "         -3.0337e-02, -1.2448e-02, -2.5501e-02,  7.3862e-02,  2.7637e-02,\n",
      "          4.5736e-02, -3.3949e-02,  5.5150e-02, -2.1823e-02, -3.0714e-02],\n",
      "        [ 1.4530e-02,  5.1788e-02,  9.4271e-02,  4.5154e-02,  7.9563e-02,\n",
      "         -1.5471e-02, -1.6142e-02,  3.8097e-02, -8.8039e-02, -5.6056e-02,\n",
      "         -9.1672e-02, -6.7972e-02, -8.8327e-02,  2.9671e-02, -1.9761e-02,\n",
      "         -1.4404e-02,  1.7756e-02,  1.3175e-02, -7.0774e-02,  4.6378e-02,\n",
      "         -7.7839e-02, -8.4415e-02, -6.2744e-02,  2.1462e-02,  8.9207e-03,\n",
      "          3.3690e-02,  7.7380e-02, -9.5911e-02,  4.4028e-02,  1.9158e-02,\n",
      "          7.5400e-02, -9.4227e-02, -7.8174e-02,  2.5910e-02,  6.7709e-02,\n",
      "          1.7122e-02, -8.1753e-02, -3.7342e-04,  3.5886e-02,  1.5764e-02,\n",
      "         -4.9754e-03, -6.5076e-03,  3.4949e-02, -3.7143e-02,  5.8938e-02,\n",
      "         -6.3589e-04,  9.8663e-03, -9.6293e-02,  4.6719e-02,  4.6153e-02,\n",
      "          8.4301e-02, -2.4950e-02,  7.0787e-02, -4.0673e-02,  8.8861e-02,\n",
      "          8.9112e-02, -8.4928e-02, -2.0021e-02, -9.0994e-02,  6.5464e-02,\n",
      "          1.8922e-02, -6.5895e-02,  1.8703e-02, -3.2714e-02,  1.6441e-02,\n",
      "         -9.1555e-02,  6.9469e-02,  9.3328e-02,  8.9816e-02,  9.0208e-02,\n",
      "         -5.1279e-02, -1.9746e-02,  2.0055e-02,  3.6679e-02,  5.4852e-02,\n",
      "         -4.6122e-02, -4.2532e-02,  3.2765e-02,  3.7495e-02, -2.1875e-02,\n",
      "         -4.8295e-02, -1.1470e-02,  8.1588e-02,  3.4839e-02, -2.4338e-02,\n",
      "          4.1573e-02,  6.3026e-02,  1.5170e-02, -3.7199e-02, -3.8454e-02,\n",
      "         -9.2925e-02, -6.8279e-02,  7.4752e-02,  2.9093e-02, -4.0434e-02,\n",
      "         -8.2903e-02, -2.7093e-03,  9.1707e-02, -3.4809e-02,  2.2403e-02],\n",
      "        [-9.5484e-02,  8.7073e-02,  7.3972e-02, -6.9917e-02,  3.8806e-02,\n",
      "          8.6631e-02,  3.2358e-02,  8.1613e-02,  4.0107e-02, -7.2415e-02,\n",
      "         -4.6553e-02,  3.2700e-02, -7.8604e-02,  5.3854e-02, -1.4607e-02,\n",
      "         -8.2761e-02, -1.2149e-02,  6.4993e-02,  9.1260e-02,  9.9972e-02,\n",
      "         -8.7242e-02,  2.9230e-02,  3.5312e-02,  8.8872e-02,  1.7638e-02,\n",
      "          3.2455e-02, -4.6684e-02,  9.1332e-02, -2.2024e-02,  9.4703e-02,\n",
      "         -6.3534e-02,  5.2066e-02,  2.5927e-02, -4.8202e-02,  8.2138e-02,\n",
      "          8.4430e-02, -5.8055e-02,  7.6147e-02,  2.2932e-02, -7.5331e-02,\n",
      "          3.8189e-03, -4.0183e-02,  2.7447e-02, -9.4413e-02, -9.1505e-02,\n",
      "         -5.3639e-02,  8.6704e-02, -5.8506e-02,  5.9607e-02, -2.2542e-02,\n",
      "          6.0154e-02, -8.7130e-02, -4.4363e-02, -1.2034e-02,  6.3850e-03,\n",
      "         -8.6664e-02,  8.9767e-02, -3.2337e-02, -4.8721e-02, -4.3603e-02,\n",
      "         -4.1184e-02, -5.2663e-02,  6.4805e-02, -7.6536e-02,  3.0101e-02,\n",
      "         -1.8226e-02,  5.2162e-02,  6.2993e-02, -9.2347e-02, -1.1845e-02,\n",
      "         -3.0793e-02,  7.8186e-03,  3.0620e-02,  5.3516e-02, -8.2588e-02,\n",
      "          5.0388e-02, -1.9655e-02,  5.4657e-02, -4.7644e-02,  3.8892e-02,\n",
      "         -7.9788e-02, -7.8459e-02, -8.8284e-02,  8.6677e-02,  5.3713e-02,\n",
      "          9.2623e-02, -3.8273e-02,  4.6105e-02, -7.5756e-03, -1.9859e-02,\n",
      "         -2.5186e-02, -4.9499e-02, -9.9224e-02,  4.9010e-02,  9.0021e-02,\n",
      "          5.5450e-03, -5.9748e-02,  7.6274e-02,  3.0908e-02,  5.7097e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0549,  0.0614,  0.0192,  0.0608, -0.0621, -0.0676, -0.0972, -0.0152,\n",
      "        -0.0497, -0.0430], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in linear_model.parameters():\n",
    "    print(parameter)\n",
    "# for name, parameter in linear_model.named_parameters():\n",
    "#     print(name, parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchinfo의 summary()\n",
    "* torchinfo 패키지의 summary()를 이용하여 보다 자세히 모델 구조를 확인 할 수 있음.\n",
    "    * model: 모델 객체\n",
    "    * input_size: 입력 tensor 사이즈. 일반적으로 batch 를 감안하여 입력. \n",
    "    * col_names: summary 수행 출력 컬럼명들. list형태로 입력.\n",
    "        * input_size: 입력 tensor size\n",
    "        * output_size: 출력 tensor size\n",
    "        * num_params: 학습 파라미터 갯수\n",
    "        * trainable: 학습 파라미터의 train 가능 설정(requires_grad) \n",
    "    * row_settings: row에 보여질 내용\n",
    "        * var_names: 모듈 변수명\n",
    "        * depth: 서브 모듈내 depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T09:03:33.592265Z",
     "iopub.status.busy": "2025-02-17T09:03:33.591990Z",
     "iopub.status.idle": "2025-02-17T09:03:33.599866Z",
     "shell.execute_reply": "2025-02-17T09:03:33.599011Z",
     "shell.execute_reply.started": "2025-02-17T09:03:33.592244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(size=(64, 784))\n",
    "print(input_tensor.size())\n",
    "\n",
    "# LinearModel 객체 생성. __init__(self, num_classes)에 선언된 객체 초기화 인자 입력하여 생성. \n",
    "linear_model = LinearModel(num_classes=10)\n",
    "\n",
    "# LinearModel 객체는 Callable Object이므로 LinearModel 객체에 함수 호출과 유사한 형태로 입력 인자 전달하여 forward()메소드 호출. \n",
    "output_tensor = linear_model(input_tensor)\n",
    "print(output_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T09:15:00.246723Z",
     "iopub.status.busy": "2025-02-17T09:15:00.246396Z",
     "iopub.status.idle": "2025-02-17T09:15:00.253861Z",
     "shell.execute_reply": "2025-02-17T09:15:00.253161Z",
     "shell.execute_reply.started": "2025-02-17T09:15:00.246693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "LinearModel (LinearModel)                [64, 784]                 [64, 10]                  --\n",
       "├─SimpleBlock (simple_01): 1-1           [64, 784]                 [64, 100]                 --\n",
       "│    └─Linear (linear_01): 2-1           [64, 784]                 [64, 100]                 78,500\n",
       "│    └─ReLU (relu_01): 2-2               [64, 100]                 [64, 100]                 --\n",
       "├─Linear (linear_02): 1-2                [64, 100]                 [64, 10]                  1,010\n",
       "===================================================================================================================\n",
       "Total params: 79,510\n",
       "Trainable params: 79,510\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 5.09\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 0.32\n",
       "Estimated Total Size (MB): 0.58\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=linear_model, input_size=(64, 784),\n",
    "        col_names=['input_size', 'output_size', 'num_params'], #'trainable'\n",
    "        row_settings=['var_names', 'depth'],\n",
    "        depth=3\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
